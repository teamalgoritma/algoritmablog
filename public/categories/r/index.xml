<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Algoritma Technical Blog</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Algoritma Technical Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Text Generation with Markov Chains</title>
      <link>/blog/text-generation-with-markov-chains/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-generation-with-markov-chains/</guid>
      <description>body {text-align: justify}IntroductionText GenerationNatural Language Processing (NLP) is a branch of artificial intelligence that is steadily growing both in terms of research and market values1. The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable2. The are many applications of NLP in various industries, such as:
SPAM email detectionSentiment AnalysisText summarizationTopic ModellingText GenerationIn this article, we will try to learn the last one: text generation.</description>
    </item>
    
    <item>
      <title>DBSCAN Clustering</title>
      <link>/blog/dbscan-clustering/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/dbscan-clustering/</guid>
      <description>body {text-align: justify}1. Pendahuluan1.1 ClusteringÂ Clustering merupakan salah satu bagian dari unsupervised learning. Clustering memiliki tujuan untuk membagi data ke dalam beberapa kelompok berdasarkan kemiripan antar data. Cluster (kelompok) yang baik adalah cluster yang memiliki kemiripan yang besar antar anggota clusternya dan memiliki perbedaan yang signifikan dengan anggota cluster yang berbeda. Clustering dapat diterapkan dalam berbagai bidang seperti segmentasi pasar, cluster profiling, data spatial dll.</description>
    </item>
    
    <item>
      <title>Optimization and Hyper-Parameter Tuning with Genetic Algorithm</title>
      <link>/blog/optimization-with-genetic-algorithm/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/optimization-with-genetic-algorithm/</guid>
      <description>IntroductionAboutOptimization is important in many fields, including in data science. In manufacturing, where every decision is critical to the process and the profit of organization, optimization is often employed, from the number of each products produced, how the unit is scheduled for production, get the best or optimal process parameter, and also the routing determination such as the traveling salesman problem. In data science, we are familiar with model tuning, where we tune our model in order to improve the model performance.</description>
    </item>
    
    <item>
      <title>Ridge and LASSO Regression</title>
      <link>/blog/ridge-lasso/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/ridge-lasso/</guid>
      <description>Overview Regression analysis is a way that can be used to determine the relationship between the predictor variable (x) and the target variable (y).
Ordinary Least Squares (OLS) is the most common estimation method for linear models and it applies for good reasons. As long as your model meets the OLS assumptions for linear regression, you can rest easy knowing that you get the best estimate.
But in the real world to meet OLS regression assumptions will be very difficult.</description>
    </item>
    
    <item>
      <title>Bioinformatics: Decoding Nature&#39;s Code of Life</title>
      <link>/blog/bio-intro/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/bio-intro/</guid>
      <description>It is inarguable that Data Science gives a tremendous impact on today&#39;s industry. Furthermore, it also accelerates the development of basic science research including Biology. Biology harbors some of the most intriguing ideas we may find today; from finding cures for genetic diseases, to something far as breeding mutants! This article will guide you through the wondrous journey of when Data Science meets Biology and how it can impact our life.</description>
    </item>
    
    <item>
      <title>Interpreting Classification Model with LIME</title>
      <link>/blog/interpreting-classification-model-with-lime/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/interpreting-classification-model-with-lime/</guid>
      <description>Introduction One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning.</description>
    </item>
    
    <item>
      <title>Text Classification with LSTM</title>
      <link>/blog/text-lstm/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-lstm/</guid>
      <description>Deep Neural Network Before we further discuss the Long Short-Term Memory Model, we will first discuss the term of Deep learning where the main idea is on the Neural Network. So Neural Network is one branch of machine learning where the learning process imitates the way neurons in the human brain works. In Neural Network we know several terms, such as the input layer, hidden layer, and output layer. So the different betweetn Deep Learning and Neural Network architecture is the number of hidden layers specified.</description>
    </item>
    
    <item>
      <title>Poisson Regression and Negative Binomial Regression</title>
      <link>/blog/poisson-regression-and-neg-ative-binomial-regression/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/poisson-regression-and-neg-ative-binomial-regression/</guid>
      <description>Introduction Regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or &amp;lsquo;predictors&amp;rsquo;).
For example   Find out the effect of land area and building area on house prices in the Kuningan region (Multiple Linear Regression)
  Find out the effect of allowance and GPA on cum laude predicate (yes or no) ?</description>
    </item>
    
    <item>
      <title>Introduction to tidymodels</title>
      <link>/blog/tidymodels/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/tidymodels/</guid>
      <description>The following presentation is produced by the team at Algoritma for its internal training This presentation is intended for a restricted audience only. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.
Outline Why tidymodels Matters?  Things we think we&#39;re doing it right Things we never think we could do it better  Setting the Cross-Validation Scheme using rsample  Rethinking: Why we need validation?</description>
    </item>
    
    <item>
      <title>Creating Choropleth with Mapshaper and R</title>
      <link>/blog/creating-choropleth-with-mapshaper-and-r/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/creating-choropleth-with-mapshaper-and-r/</guid>
      <description>Geospatial is one of the important things in data processing. With geospatial, we can provide information only with the help of maps so that information can be conveyed properly.
There are many types of geospatial that we can do, such as Dot Map, Connection Map, Choropleth, Hexbin Map, and Bubble Map1. Each type of geospatial has its own function, and each of these types also requires different types of information/data.</description>
    </item>
    
    <item>
      <title>Self-Organizing Maps</title>
      <link>/blog/self-organizing-maps/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/self-organizing-maps/</guid>
      <description>Introduction SOM Self-Organizing Maps first introduce by Teuvo Kohonen. According to the Wiki, Self-Organizing Map (SOM) or self-organizing feature map (SOFM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a map, and is therefore a method to do dimensionality reduction. SOM are an unsupervised data visualisation technique that can be used to visualise high-dimensional data sets in lower (typically 2) dimensional representations.</description>
    </item>
    
    <item>
      <title>Age-Period-Cohort (APC) Analysis</title>
      <link>/blog/age-period-cohort-apc-analysis/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/age-period-cohort-apc-analysis/</guid>
      <description>Background Disclaimer The following coursebook is produced by the team at Algoritma for its Data Science Academy internal training. The coursebook is intended for a restricted audience only, i.e. the individuals and organizations having received this coursebook directly from the training organization. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.
Libraries and Setup You will need install the package to do APC analysis if it&#39;s not already downloaded onto your machine.</description>
    </item>
    
    <item>
      <title>Twitter Interactions Analysis using Twinetverse</title>
      <link>/blog/twitter-interactions-analysis-using-twinetverse/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/twitter-interactions-analysis-using-twinetverse/</guid>
      <description>IntroductionThe goal of the twinetverse is to provide everything one might need to view Twitter interactions, from data collection to visualisation. This could be a powerful tool for social media analysis, since it could help visualizing how users communicate with one another on a given topic or how information spreads throughout the Twitter network.</description>
    </item>
    
    <item>
      <title>Purrr-operly Fitting Multiple Time Series Model</title>
      <link>/blog/purrr-operly-fitting-multiple-time-series-model/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/purrr-operly-fitting-multiple-time-series-model/</guid>
      <description>In this article, I will explain some basic functional programming for fitting multiple time series using R, particularly using purrr interface.
TL;DR: you can find the distraction-free script in here, and read some of my concluding remarks for a quick summary :grin:
PrefaceWhen it comes to time series analyses and forecasting, R users are blessed with an invaluable tools that could helps us to conveniently fitâfrom basic to advancedâunivariate time series models: forecast package.</description>
    </item>
    
    <item>
      <title>Data Wars: Episode IV</title>
      <link>/blog/data-wars-episode-iv/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/data-wars-episode-iv/</guid>
      <description>Data wrangling sometimes could become very tedious. No matter what language do you prefer: R, python, or even SQL, the process of preprocessing your dataset is generally very time consuming. But, this is not the case if you know how to properly use packages included in tidyverse.
The term of tidyverse is actually referring to a set of packages that youâll find very helpful in any data analysis tasks; many of them are already popular among R users, like dplyr, ggplot2, and lubridate.</description>
    </item>
    
    <item>
      <title>Text Preprocessing using textclean</title>
      <link>/blog/textclean/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/textclean/</guid>
      <description>Take tweet from twitter using rtweet packageFunction used for take tweet from twitter is search_tweets(). There are several parameter usually used in that function: - Topic : topic you will find at twitter - n : how many tweet that you want to take - include_rts : logical. If FALSE tweet taken didnât contain retweet - lang : spesified language. If you want take tweet in english you can addargument lang = âenâ You can use this code below to try taking tweets from twitter by removing the command</description>
    </item>
    
    <item>
      <title>Handling Duplicate Data</title>
      <link>/blog/handling-duplicate-data/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/handling-duplicate-data/</guid>
      <description>Reading Data and Basic PreprocessingSome data that we obtain from the internet are gained as a raw, means that there are no modifications done to the data except placing it in the right column or row. Even if thatâs a good thing, sometimes you have to treat and change the template of the data to be as friendly to reach our objective as possible.
Making sure that there are no duplicated data is one of the aspect of understanding the data itself, because we canât say that the model that are being made from the information full of duplicated data is relevant enough to be used in real-case scenario.</description>
    </item>
    
    <item>
      <title>Time Series Prediction with LSTM</title>
      <link>/blog/time-series-prediction-with-lstm/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/time-series-prediction-with-lstm/</guid>
      <description>Time Series Forecasting using LSTMTime series involves data collected sequentially in time. In Feed Forward Neural Network we describe that all inputs are not dependent on each other or are usually familiar as IID (Independent Identical Distributed), so it is not appropriate to use sequential data processing.A Recurrent Neural Network (RNN) deals with sequence problems because their connections form a directed cycle.</description>
    </item>
    
    <item>
      <title>Metrics Evaluation using `yardstick`</title>
      <link>/blog/metrics-evaluation-using-yardstick/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/metrics-evaluation-using-yardstick/</guid>
      <description>MotivationEvaluating your machine learning algorithms is important part in your project. Choice of metrics influences how the performance of machine learning algorithms is measured and compared. Metrics evaluation used to measure the performance of our algorithms. For Regression models, we usually use R-squared and MSE, but for Classification models we can use precision, recall and accuracy. Evaluating a classifier is often much more difficult than evaluating a regression algorithm.</description>
    </item>
    
    <item>
      <title>Nested Dataframe</title>
      <link>/blog/nested-dataframe/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/nested-dataframe/</guid>
      <description>1. SetupLibraries and SetupWeâll set-up caching for this notebook given how computationally expensive some of the code we will write can get.
You will need to use install.packages() to install any packages that are not already downloaded onto your machine. You then load the package into your workspace using the library() function:
library(tidyverse)library(caret)2. Nested DataframeYouâll learn how to use purrr, caret and dplyr to quickly create some of dataset + model combinations, store data &amp;amp; model objects neatly in one tibble, and post process programatically.</description>
    </item>
    
    <item>
      <title>Troubleshoot in R</title>
      <link>/blog/troubleshoot-in-r/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/troubleshoot-in-r/</guid>
      <description>IntroductionWhen you start coding in R you probably get a lot of errors, and trying to decipher an error can be a time-consuming task. You might need to Google or maybe you asked for help to your friends/mentor and they find out youâve forgot a closing bracket!.
You just learnt about the importance of it just few hours ago, âYouâre supposed to know this stuffâ. You might be frustrated and blame yourself when you make very basic mistakes, but this is something every one goes through.</description>
    </item>
    
    <item>
      <title>Forecasting Time Series with Multiple Seasonal</title>
      <link>/blog/multiple-seasonal/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/multiple-seasonal/</guid>
      <description>IntroductionTime Series Analysis describes a set of research problems where our observations are collected at regular time intervals and where we can assume correlations among successive observations. The principal idea is to learn from these past observations any inherent structures or patterns within the data, with the objective of generating future values for the series. Time series may contain multiple seasonal cycles of different lengths. A fundamental goal for multiple seasonal (MS) processes is to allow for the seasonal terms that represent a seasonal cycle to be updated more than once during the period of the cycle.</description>
    </item>
    
    <item>
      <title>Text Cleaning Bahasa Indonesia-based Twitter Data</title>
      <link>/blog/text-cleaning-bahasa/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-cleaning-bahasa/</guid>
      <description>Social media has become a very popular spot for data mining these last years. But when we talk about social data, we actually also talk about unstructured data, and in order to derive any meaningful insight from it, we have to know how to work with it in its unstructured form (or in this case, unstructured text information).
Before the data we gather can be used for further analysis, the very first step to do is to clean the data.</description>
    </item>
    
    <item>
      <title>Causal Inference and Bayesian Network</title>
      <link>/blog/causal-inference-and-bayesian-network/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/causal-inference-and-bayesian-network/</guid>
      <description>Introduction Cause has been people&#39;s curiosity for a long time, you can see that people often ask &amp;ldquo;Why&amp;rdquo; to things happening around them. But do we actually know how to explain &amp;ldquo;cause&amp;rdquo;?
Do we jump to conclusion of causal relationship often too quickly?
Can association between factors that we call mathematically &amp;ldquo;correlation&amp;rdquo; tell us possible causal relationship? No. Correlation shows whether two variable go up or down together. But just because two variables go up together doesn&#39;t mean it affects each other.</description>
    </item>
    
    <item>
      <title>Support Vector Machine</title>
      <link>/blog/support-vector-machine/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/support-vector-machine/</guid>
      <description>Support Vector Machine (SVM) Support Vector Machine is a Supervised Machine Learning Algorithm which can be used both classification and regression. In this algorithm, each data item is plotted as point in n-dimensional space with the value of each feature being the value of a particular coordinate. Then, the algorithm perform classification by finding the hyper-plane that differentiate the two classes very well.
So how does SVM find the right hyperplane?</description>
    </item>
    
  </channel>
</rss>