<!DOCTYPE HTML>

<html>
    <head>
        <script type="application/ld+json">
    {
        "@context" : "http://schema.org",
        "@type" : "BlogPosting",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "\/"
        },
        "articleSection" : "blog",
        "name" : "Interpreting Classification Model with LIME",
        "headline" : "Interpreting Classification Model with LIME",
        "description" : "Introduction One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning.",
        "inLanguage" : "en",
        "author" : "",
        "creator" : "",
        "publisher": "",
        "accountablePerson" : "",
        "copyrightHolder" : "",
        "copyrightYear" : "2019",
        "datePublished": "2019-12-02 00:00:00 \x2b0000 UTC",
        "dateModified" : "2019-12-02 00:00:00 \x2b0000 UTC",
        "url" : "\/blog\/interpreting-classification-model-with-lime\/",
        "wordCount" : "2437",
        "keywords" : [ "Machine Learning","Capstone Ml","tidymodels","lime","Blog" ]
    }
    </script>
        
            
                <title>Interpreting Classification Model with LIME</title>
            
        

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="generator" content="Hugo 0.60.1" />
        


        
            <meta name="author" content="Arga Adyatama">
        
        
            
                <meta name="description" content="HTML5 UP theme, Future Imperfect with some extra goodies, ported by Julio Pescador. Powered by Hugo">
            
        

        <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Interpreting Classification Model with LIME"/>
<meta name="twitter:description" content="Introduction One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning."/>
<meta name="twitter:site" content="@teamalgoritma"/>

        <meta property="og:title" content="Interpreting Classification Model with LIME" />
<meta property="og:description" content="Introduction One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/interpreting-classification-model-with-lime/" />
<meta property="article:published_time" content="2019-12-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-12-02T00:00:00+00:00" />

        <meta property="og:image" content="//images/logo.png">
        <meta property="og:image:type" content="image/png">
        <meta property="og:image:width" content="512">
        <meta property="og:image:height" content="512">
        <meta itemprop="name" content="Interpreting Classification Model with LIME">
<meta itemprop="description" content="Introduction One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning.">
<meta itemprop="datePublished" content="2019-12-02T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-12-02T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="2437">



<meta itemprop="keywords" content="Machine Learning,Capstone Ml,tidymodels,lime," />
        

        
            
        

        
        
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">
            <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
            <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.css">
            <link rel="stylesheet" href="/css/main.css">
            <link rel="stylesheet" href="/css/add-on.css">
            <link rel="stylesheet" href="/css/academicons.min.css">
        

        
            
                
            
                
                    <link rel="stylesheet" href="/css/night-owl.css">
                
            
        


  
    
      <link rel="stylesheet" href="/css/night-owl.css" rel="stylesheet" id="theme-stylesheet">
      <script src="/js/highlight.pack.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>
  


      





    </head>
    <body>

      
      <div id="wrapper">

    
    
<header id="header">
    
      <h1><a href="/">blog</a></h1>
    

    <nav class="links">
        <ul>
            
                <li>
                    <a href="/">
                            <i class="fa fa-home">&nbsp;</i>Home
                    </a>
                </li>
            
                <li>
                    <a href="/tags/machine-learning/">
                            <i class="fa fa-cog">&nbsp;</i>Machine Learning
                    </a>
                </li>
            
                <li>
                    <a href="/tags/data-visualization/">
                            <i class="fa fa-area-chart">&nbsp;</i>Data Visualization
                    </a>
                </li>
            
        </ul>
    </nav>
    <nav class="main">
        <ul>
            
            <li id="share-nav" class="share-menu" style="display:none;">
                <a class="fa-share-alt" href="#share-menu">Share</a>
            </li>
            
            <li class="search">
                <a class="fa-search" href="#search">Search</a>
                <form id="search" method="get" action="//google.com/search">
                    <input type="text" name="q" placeholder="Search" />
                    <input type="hidden" name="as_sitesearch" value="/">
                </form>
            </li>
            <li class="menu">
                <a class="fa-bars" href="#menu">Menu</a>
            </li>
        </ul>
    </nav>
</header>


<section id="menu">

    
        <section>
            <form class="search" method="get" action="//google.com/search">
                <input type="text" name="q" placeholder="Search" />
                <input type="hidden" name="as_sitesearch" value="/">
            </form>
        </section>

    
        <section>
            <ul class="links">
                
                    <li>
                        <a href="/">
                            <h3>
                                <i class="fa fa-home">&nbsp;</i>Home
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags/machine-learning/">
                            <h3>
                                <i class="fa fa-cog">&nbsp;</i>Machine Learning
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags/data-visualization/">
                            <h3>
                                <i class="fa fa-area-chart">&nbsp;</i>Data Visualization
                            </h3>
                        </a>
                    </li>
                
            </ul>
        </section>

    
        <section class="recent-posts">
            <div class="mini-posts">
                <header>
                    <h3>Recent Posts</h3>
                </header>
                

                
                    
                

                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/text-generation-with-markov-chains/">Text Generation with Markov Chains</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-04-02'>
                                    April 2, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/dbscan-clustering/">DBSCAN Clustering</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-02-07'>
                                    February 7, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/optimization-with-genetic-algorithm/">Optimization and Hyper-Parameter Tuning with Genetic Algorithm</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-01-13'>
                                    January 13, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/introduction-to-generative-adversarial-network-with-keras/">Introduction to Generative Adversarial Network with Keras</a></h3>
                                
                                <time class="published" datetime=
                                    '2019-12-18'>
                                    December 18, 2019</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/ridge-lasso/">Ridge and LASSO Regression</a></h3>
                                
                                <time class="published" datetime=
                                    '2019-12-18'>
                                    December 18, 2019</time>
                            </header>
                            

                        </article>
                

                
                    <a href=
                        
                            /blog/
                        
                        class="button">View more posts</a>
                
            </div>
        </section>

    
        
</section>

    <section id="share-menu">
    <section id="social-share-nav">
        <ul class="links">
            <header>
                <h3>Share this post <i class="fa fa-smile-o"></i></h3>
            </header>
            



<li>
  <a href="https://twitter.com/intent/tweet?text=Interpreting%20Classification%20Model%20with%20LIME&amp;url=%2fblog%2finterpreting-classification-model-with-lime%2f" target="_blank" class="share-btn twitter">
    <i class="fa fa-twitter"></i>
    <p>Twitter</p>
    </a>
</li>








<li>
  <a href="https://www.facebook.com/sharer.php?u=%2fblog%2finterpreting-classification-model-with-lime%2f" target="_blank" class="share-btn facebook">
    <i class="fa fa-facebook"></i>
    <p>Facebook</p>
    </a>
</li>







<li>
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2finterpreting-classification-model-with-lime%2f&amp;title=Interpreting%20Classification%20Model%20with%20LIME" target="_blank" class="share-btn linkedin">
      <i class="fa fa-linkedin"></i>
      <p>LinkedIn</p>
    </a>
</li>











        </ul>
    </section>
</section>

    
    <div id="main">
        
        
        <article class="post">
  <header>
    <div class="title">
        
            <h2><a href="/blog/interpreting-classification-model-with-lime/">Interpreting Classification Model with LIME</a></h2>
        
        
    </div>
    <div class="meta">
        

        <time class="published"
            datetime='2019-12-02'>
            December 2, 2019</time>
        <span class="author"><a href="https://github.com/Argaadya">Arga Adyatama</a></span>
        
            <p>12 minute read</p>
        
        
    </div>
</header>


  
    <section id="social-share">
      <ul class="icons">
        



<li>
  <a href="https://twitter.com/intent/tweet?text=Interpreting%20Classification%20Model%20with%20LIME&amp;url=%2fblog%2finterpreting-classification-model-with-lime%2f" target="_blank" class="share-btn twitter">
    <i class="fa fa-twitter"></i>
    <p>Twitter</p>
    </a>
</li>








<li>
  <a href="https://www.facebook.com/sharer.php?u=%2fblog%2finterpreting-classification-model-with-lime%2f" target="_blank" class="share-btn facebook">
    <i class="fa fa-facebook"></i>
    <p>Facebook</p>
    </a>
</li>







<li>
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2finterpreting-classification-model-with-lime%2f&amp;title=Interpreting%20Classification%20Model%20with%20LIME" target="_blank" class="share-btn linkedin">
      <i class="fa fa-linkedin"></i>
      <p>LinkedIn</p>
    </a>
</li>











      </ul>
    </section>
  

  
    

    
        
        







  
  
    
  


        
        
        

        <a href="/blog/interpreting-classification-model-with-lime/" class="image featured">
            <img src="/img/2019/12/lime.png" alt="">
        </a>
    


  <div id="content">
    <h1 id="introduction">Introduction</h1>
<p>One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning. The downside is, in general, interpretable model has lower performance in term of accuracy or precision, making them less useful and potentially dangerous for production. Therefore, there is a growing need on how to interpret a complex and black box model easily.</p>
<p>There exist a method called LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. Here we will see how LIME works on binary classification problem of employee attrition. By understanding on how our model works, we can have more advantage and could act wiser on what should we do.</p>
<h1 id="local-interpretable-modelagnostic-explanations-lime">Local Interpretable Model-Agnostic Explanations (LIME)</h1>
<h2 id="lime-characteristics">LIME characteristics</h2>
<p>Let's understand some of the LIME characteristic (Ribeiro et al., 2016):</p>
<ul>
<li><strong>Interpretable</strong></li>
</ul>
<p>Provide qualitative understanding between the input variables and the response. Interpretability must take into account the user’s limitations. Thus, a linear model, a gradient vector or an additive model may or may not be interpretable. For example, if hundreds or thousands of features significantly contribute to a prediction, it is not reasonable to expect any user to comprehend why the prediction was made, even if individual weights can be inspected. This requirement further implies that explanations should be easy to understand, which is not necessarily true of the features used by the model, and  thus the “input variables” in the explanations may need to be different than the features. Finally, the notion of interpretability also depends on the target audience. Machine learning practitioners may be able to interpret small Bayesian networks, but laymen may be more comfortable with a small number of weighted features as an explanation.</p>
<ul>
<li><strong>Local Fidelity</strong></li>
</ul>
<p>Although it is often impossible for an explanation to be completely faithful unless it is the complete description of the model itself, for an explanation to be meaningful it must at least be locally faithful, i.e. it must correspond to how the model behaves in the vicinity of the instance being predicted. We note that local fidelity does not imply global fidelity: features that are globally important may not be important in the local context, and vice versa. While global fidelity would imply local fidelity, identifying globally faithful explanations that are interpretable remains a challenge for complex models.</p>
<ul>
<li><strong>Model-Agnostic</strong></li>
</ul>
<p>An explainer should be able to explain any model, and thus be model-agnostic (i.e. treat the original model as a black box). Apart from the fact that many state of the art classifiers are not currently interpretable, this also provides flexibility to explain future classifiers.</p>
<h2 id="how-lime-works">How LIME works</h2>
<p>The generalized algorithm LIME applies is (Boehmke, 2018):</p>
<p>(1) Given an observation, permute it to create replicated feature data with slight value modifications.
(2) Compute similarity distance measure between original observation and permuted observations.
(3) Apply selected machine learning model to predict outcomes of permuted data.
(4) Select m number of features to best describe predicted outcomes.
(5) Fit a simple model to the permuted data, explaining the complex model outcome with m features from the permuted data weighted by its similarity to the original observation .
(6) Use the resulting feature weights to explain local behavior.</p>
<p>For more detailed description on how LIME work, you can check Ribeiro et al. paper works (<a href="https://arxiv.org/abs/1602.04938">https://arxiv.org/abs/1602.04938</a>)</p>
<h1 id="lime-packages-in-r"><code>lime</code> packages in R</h1>
<p>You can implement LIME in R with <code>lime</code> package.  See <a href="https://github.com/thomasp85/lime">https://github.com/thomasp85/lime</a>.</p>
<p>Here is the list of packages you need to load before proceeding to the next section.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">library</span>(tidyverse)
<span style="color:#a6e22e">library</span>(tidymodels)
<span style="color:#a6e22e">library</span>(lime)
<span style="color:#a6e22e">library</span>(rmarkdown)
</code></pre></div><h2 id="example-binary-classification">Example: Binary Classification</h2>
<p>Let's how LIME work on <code>IBM HR attrition</code> dataset from Kaggle (<a href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)">https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)</a>. We want to correctly target people who are likely to resign. We want to know what factors that drive people to resign/attrition and propose a plan to reduce the number of turnover next year. In order to effectively reduce turnover rate as many as possible, we want our model to have high Recall/Sensitivity.</p>
<h3 id="import-data">Import Data</h3>
<p>The data consists of information related to the employee who works from the company. Attrition refers to employees who quite the organization.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">attrition <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">read.csv</span>(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">data_input/attrition.csv&#34;</span>)
<span style="color:#a6e22e">paged_table</span>(attrition)
</code></pre></div><!-- raw HTML omitted -->
<h3 id="data-preprocessing-1">Data Preprocessing 1</h3>
<p>Before do create our model, here is some of data wrangling that is done:</p>
<ul>
<li>Sum all of the satisfaction score into <code>total_satisfaction</code></li>
<li>Transform <code>education</code> into factor and rename each value (1 = Below College, 2 = College, 3 = Bachelor, 4 = Master, 5 = Doctor)</li>
<li>Transform <code>job_level</code> and <code>stock_option_level</code> into factor</li>
<li>Transform <code>age</code> into 3 level factors: Young (less than 25), Middle Age (25-54), and Senior (more than 54)</li>
<li>Transform <code>monthly_income</code> into 2 level factors: Below average and Above average)</li>
<li>Adjust the level of <code>attrition</code>, with the first level will be the positive class (<code>attrition = yes</code>)</li>
<li>Remove unnecessary variables</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">df <span style="color:#f92672">&lt;-</span> attrition
df<span style="color:#f92672">$</span>total_satisfaction <span style="color:#f92672">&lt;-</span> df <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">group_by</span>(employee_number) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">summarise</span>(total_satisfaction <span style="color:#f92672">=</span> <span style="color:#a6e22e">sum</span>(environment_satisfaction, job_satisfaction, performance_rating,
                                  work_life_balance, job_involvement, relationship_satisfaction)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">pull</span>(<span style="color:#ae81ff">2</span>)

df <span style="color:#f92672">&lt;-</span> df <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">mutate</span>(education <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.factor</span>(<span style="color:#a6e22e">case_when</span>(education <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Below College&#34;</span>,
                                         education <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">College&#34;</span>,
                                         education <span style="color:#f92672">==</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Bachelor&#34;</span>,
                                         education <span style="color:#f92672">==</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Master&#34;</span>,
                                         <span style="color:#66d9ef">TRUE</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Doctor&#34;</span>)),
         age <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.factor</span>(<span style="color:#a6e22e">case_when</span>(age <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">25</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Young&#34;</span>,
                                   age <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">54</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Middle Aged&#34;</span>,
                                   <span style="color:#66d9ef">TRUE</span> <span style="color:#f92672">~</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Senior&#34;</span>)),
         monthly_income <span style="color:#f92672">=</span> <span style="color:#a6e22e">if_else</span>(monthly_income <span style="color:#f92672">&lt;</span> <span style="color:#a6e22e">median</span>(monthly_income), <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Below Average&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Above Average&#34;</span>),
         job_level <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.factor</span>(job_level),
         stock_option_level <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.factor</span>(stock_option_level),
         attrition <span style="color:#f92672">=</span> <span style="color:#a6e22e">factor</span>(attrition, levels <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">yes&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">no&#34;</span>))) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">select</span>(<span style="color:#f92672">-</span><span style="color:#a6e22e">c</span>(environment_satisfaction, job_satisfaction, performance_rating, employee_number,
            work_life_balance, job_involvement, relationship_satisfaction))

<span style="color:#a6e22e">paged_table</span>(df)
</code></pre></div><!-- raw HTML omitted -->
<h3 id="crossvalidation">Cross-Validation</h3>
<p>First we check if there is a class imbalance</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">prop.table</span>(<span style="color:#a6e22e">table</span>(df<span style="color:#f92672">$</span>attrition))
</code></pre></div><pre><code>#&gt; 
#&gt;       yes        no 
#&gt; 0.1612245 0.8387755
</code></pre><p>We split the data into training set and testing dataset, with 80% of the data will be used as the training set. The cross-validation, preprocessing, modeling, and evalution is done using various functions from <code>tidymodels</code> package. If you are unfamiliar with this, you can read our post about <code>tidymodels</code> <!-- raw HTML omitted --> here <!-- raw HTML omitted -->.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">123</span>)
intrain <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">initial_split</span>(df, prop <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.8</span>, strata <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">attrition&#34;</span>)

intrain
</code></pre></div><pre><code>#&gt; &lt;1177/293/1470&gt;
</code></pre><h3 id="data-preprocessing-2">Data Preprocessing 2</h3>
<p>We will further preprocess the data with the following steps using <code>recipe()</code> function from <code>recipes</code> package.</p>
<ul>
<li>Downsample to prevent class imbalance</li>
<li>Remove <code>over_18</code> variable since it only has 1 levels of factor</li>
<li>Scaling all of the numeric variables</li>
<li>Remove numeric variable with near zero variance</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># Preprocess Recipes</span>
rec <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">recipe</span>(attrition <span style="color:#f92672">~</span> ., data <span style="color:#f92672">=</span> <span style="color:#a6e22e">training</span>(intrain)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">step_downsample</span>(attrition) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">step_rm</span>(over_18) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">step_scale</span>(<span style="color:#a6e22e">all_numeric</span>()) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">step_nzv</span>(<span style="color:#a6e22e">all_numeric</span>()) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">prep</span>()

<span style="color:#75715e"># Create Data Train and Data Test</span>
data_train <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">juice</span>(rec)
data_test <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">bake</span>(rec, <span style="color:#a6e22e">testing</span>(intrain))
</code></pre></div><p>For later implementation, we create a <code>rec_rev</code> to back transform our data that has already preprocessed with <code>recipes</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># Prepare the reverse recipes</span>

rec_rev <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x){
  
  y <span style="color:#f92672">&lt;-</span> x <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">select_if</span>(is.numeric)
  
  <span style="color:#a6e22e">for </span>(i in <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#a6e22e">length</span>(<span style="color:#a6e22e">names</span>(y))) {
    y[ , i] <span style="color:#f92672">&lt;-</span> y[ ,i] <span style="color:#f92672">*</span> rec<span style="color:#f92672">$</span>steps[[3]]<span style="color:#f92672">$</span>sds<span style="color:#a6e22e">[names</span>(y)[i]]
  }
  
  x <span style="color:#f92672">&lt;-</span> x <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">select_if</span>(is.factor) <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">bind_cols</span>(y)
  <span style="color:#a6e22e">return</span>(x)
}
</code></pre></div><h3 id="model-fitting">Model Fitting</h3>
<p>We will use random Forest to predict if an employee will turnover (<code>attrition = yes</code>).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e">#define model spec</span>
model_spec <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rand_forest</span>(
  mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">classification&#34;</span>,
  mtry <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>,
  trees <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>,
  min_n <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>)

<span style="color:#75715e">#define model engine</span>
model_spec <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">set_engine</span>(model_spec,
                         engine <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">ranger&#34;</span>,
                         seed <span style="color:#f92672">=</span> <span style="color:#ae81ff">123</span>,
                         num.threads <span style="color:#f92672">=</span> parallel<span style="color:#f92672">::</span><span style="color:#a6e22e">detectCores</span>(),
                         importance <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">impurity&#34;</span>)

<span style="color:#75715e">#model fitting</span>
<span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">123</span>)
model <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">fit_xy</span>(
  object <span style="color:#f92672">=</span> model_spec,
  x <span style="color:#f92672">=</span> <span style="color:#a6e22e">select</span>(data_train, <span style="color:#f92672">-</span>attrition),
  y <span style="color:#f92672">=</span> <span style="color:#a6e22e">select</span>(data_train, attrition)
)
</code></pre></div><h3 id="model-evaluation">Model Evaluation</h3>
<p>Let's check the model performance.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">pred_test <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">predict</span>(model, new_data <span style="color:#f92672">=</span> data_test <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">select</span>(<span style="color:#f92672">-</span>attrition)) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">bind_cols</span>(true <span style="color:#f92672">=</span> data_test<span style="color:#f92672">$</span>attrition)

pred_test <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">summarise</span>(accuracy <span style="color:#f92672">=</span> <span style="color:#a6e22e">accuracy_vec</span>(true, .pred_class),
            sensitivity <span style="color:#f92672">=</span> <span style="color:#a6e22e">sens_vec</span>(true, .pred_class),
            precision <span style="color:#f92672">=</span> <span style="color:#a6e22e">precision_vec</span>(true, .pred_class),
            specificity <span style="color:#f92672">=</span> <span style="color:#a6e22e">spec_vec</span>(true, .pred_class))
</code></pre></div><pre><code>#&gt; # A tibble: 1 x 4
#&gt;   accuracy sensitivity precision specificity
#&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
#&gt; 1    0.744       0.745     0.357       0.744
</code></pre><p>We've stated that we want to save as many employees as possible from turnover. Therefore, we want those who potentially would resign should be correctly predicted as many as possible. That's why we need to be concerned with the Sensitivity or Recall value of our model. Based on the model performance, 76% of employees who would resign are correctly predicted.</p>
<p>Intuitively, you can check the importance of each variable from the model based on the <code>impurity</code> of each variables. Variable importance quantifies the global contribution of each input variable to the predictions of a machine learning model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># get variable importance</span>
var_imp <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">tidy</span>(model<span style="color:#f92672">$</span>fit<span style="color:#f92672">$</span>variable.importance) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">arrange</span>(<span style="color:#a6e22e">desc</span>(x))

<span style="color:#75715e"># tidying</span>
var_imp <span style="color:#f92672">&lt;-</span> var_imp <span style="color:#f92672">%&gt;%</span>
  <span style="color:#a6e22e">head</span>(<span style="color:#ae81ff">10</span>) <span style="color:#f92672">%&gt;%</span> 
  <span style="color:#a6e22e">rename</span>(variable <span style="color:#f92672">=</span> names, importance <span style="color:#f92672">=</span> x) <span style="color:#f92672">%&gt;%</span>
  <span style="color:#a6e22e">mutate</span>(variable <span style="color:#f92672">=</span> <span style="color:#a6e22e">reorder</span>(variable, importance))

<span style="color:#75715e"># variable importance plot</span>
<span style="color:#a6e22e">ggplot</span>(var_imp, <span style="color:#a6e22e">aes</span>(x <span style="color:#f92672">=</span> variable, y <span style="color:#f92672">=</span> importance)) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">geom_col</span>(<span style="color:#a6e22e">aes</span>(fill <span style="color:#f92672">=</span> importance), show.legend <span style="color:#f92672">=</span> F) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">geom_text</span>(<span style="color:#a6e22e">aes</span>(label <span style="color:#f92672">=</span> <span style="color:#a6e22e">round</span>(importance, <span style="color:#ae81ff">2</span>)), nudge_y <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>)<span style="color:#f92672">+</span>
  <span style="color:#a6e22e">coord_flip</span>() <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">labs</span>(title <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Variables Importance (Top 10)&#34;</span>, x <span style="color:#f92672">=</span> <span style="color:#66d9ef">NULL</span>, y <span style="color:#f92672">=</span> <span style="color:#66d9ef">NULL</span>, fill <span style="color:#f92672">=</span> <span style="color:#66d9ef">NULL</span>) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">scale_y_continuous</span>(expand <span style="color:#f92672">=</span> <span style="color:#a6e22e">expand_scale</span>(mult <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.1</span>))) <span style="color:#f92672">+</span>
  <span style="color:#a6e22e">scale_fill_viridis_c</span>()<span style="color:#f92672">+</span>
  <span style="color:#a6e22e">theme_minimal</span>()
</code></pre></div><p><!-- raw HTML omitted --></p>
<p>However, variable importance measures rarely give insight into the average direction that a variable affects a response function. They simply state the magnitude of a variable’s relationship with the response as compared to other variables used in the model. We can't know specifically the influence of each factors for a single observation (no local-fidelity). That's why we need LIME to help us understand individually what makes people resign.</p>
<h3 id="use-lime-to-interpret-random-forest-model">Use LIME to Interpret Random Forest Model</h3>
<p>Let's use LIME to interpret the model. Here we will use example of the first 4 observations from our testing dataset (<code>data_test</code>).</p>
<p>We want to see how our model classify an observations likelihood to resign (<code>labels = &quot;yes&quot;</code>) with only 10 features that has the most contribution toward the probability (<code>n_features = 10</code>). Here we use the previous <code>rec_rev</code> function in order to back transform the preprocessed data so we can interpret them easily.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">123</span>)
explainer <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lime</span>(x <span style="color:#f92672">=</span> <span style="color:#a6e22e">rec_rev</span>(data_train) <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">select</span>(<span style="color:#f92672">-</span>attrition), 
                  model <span style="color:#f92672">=</span> model)
</code></pre></div><p>Some parameter you can adjust in <code>lime</code> function:</p>
<ul>
<li><code>x</code> =  Dataset that is used to train the model.</li>
<li><code>model</code> = The machine learning model we want to explain</li>
<li><code>bin_continuous</code> = Logical value indicating if numerical variable should be binned into several groups</li>
<li><code>n_bins</code> = Number of bins for continuous variables</li>
</ul>
<p>We then select the object we want to explain (the testing dataset).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">explanation <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">explain</span>(x <span style="color:#f92672">=</span> <span style="color:#a6e22e">rec_rev</span>(data_test) <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">select</span>(<span style="color:#f92672">-</span>attrition) <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">slice</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">4</span>), 
                       labels <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">yes&#34;</span>,
                       explainer <span style="color:#f92672">=</span> explainer, 
                       n_features <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>)
</code></pre></div><p>Some parameters you can adjust in <code>explanation</code> function:</p>
<ul>
<li><code>x</code> = The object you want to explain</li>
<li><code>labels</code> = What specific labels of the target variables you want to explain</li>
<li><code>explainer</code> = the explainer object from <code>lime</code> function</li>
<li><code>n_features</code> = number of features used to explain the data</li>
<li><code>n_permutations</code> = number of permutations for each observation for explanation. THe default is 5000 permutations</li>
<li><code>dist_fun</code> = distance function used to calculate the distance to the permutation. The default is Gower’s distance but can also use euclidean, manhattan, or any other distance function allowed by ?dist()</li>
<li><code>kernel_width</code> = An exponential kernel of a user defined width (defaults to 0.75 times the square root of the number of features) used to convert the distance measure to a similarity value</li>
</ul>
<p>Finally, we plot the explanation with <code>plot_features</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">plot_features</span>(explanation)
</code></pre></div><p><!-- raw HTML omitted --></p>
<p>The text <code>Label: yes</code> shows what value of target variable is being explained. The <code>Probability</code> shows the probability of the observation belong to the label <code>yes</code>. We can see that for all observations they have little probability, so the model would predict them as <code>no</code> instead of yes. You may check them on the object <code>pred_test</code> that we've previously created.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">pred_test[1<span style="color:#f92672">:</span><span style="color:#ae81ff">4</span>, ]
</code></pre></div><pre><code>#&gt; # A tibble: 4 x 2
#&gt;   .pred_class true 
#&gt;   &lt;fct&gt;       &lt;fct&gt;
#&gt; 1 no          no   
#&gt; 2 yes         yes  
#&gt; 3 no          no   
#&gt; 4 no          yes
</code></pre><p>Below all of those label there is a bar plot, with y-axis shows each selected features while x-axis is the weight of each respective features. The color of each bar represent whether the features <strong>support</strong> or <strong>contradict</strong> if the observations labeled as <strong>yes</strong>. The interpretation is quite simple. For example, for observation 1, <code>over_time = no</code> has the biggest weight to contradict the attrition to be <strong>yes</strong>. This mean that the employee has no over time job and less likely to turnover. On the other hand, the <code>training_times_last_year &lt;=2</code> support the likelihood to resign, suggesting that employee want more training for self-improvement.</p>
<p>The next element is <code>Explanation Fit</code>. These values indicate how good LIME explain the model, kind of like the <code>\(R^2\)</code> (R-Squared) value of linear regression. Here we see the <code>Explanation Fit</code> only has values around 0.30-0.40 (30%-40%), which can be interpreted that LIME can only explain a little about our model. You may consider not to trust the LIME output since it only has low <code>Explanation Fit</code>. However, you can improve the <code>Explanation Fit</code> by tuning the <code>explain</code> function parameter.</p>
<p>Here we tune the LIME by increasing the number of permutations into 500 (<code>n_permutations = 500</code>). The distance function is changed into manhattan distance (<code>dist_fun = manhattan</code>) and the kernel width into 3 (<code>kernel_width - 3</code>).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">123</span>)

explanation <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">explain</span>(<span style="color:#a6e22e">rec_rev</span>(data_test) <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">select</span>(<span style="color:#f92672">-</span>attrition) <span style="color:#f92672">%&gt;%</span> <span style="color:#a6e22e">slice</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">4</span>), 
                       labels <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">yes&#34;</span>,
                       n_permutations <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>,
                       dist_fun <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">manhattan&#34;</span>,
                       explainer <span style="color:#f92672">=</span> explainer, 
                       kernel_width <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>,
                       n_features <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>)

<span style="color:#a6e22e">plot_features</span>(explanation)
</code></pre></div><p><!-- raw HTML omitted --></p>
<p>The <code>Explanation Fit</code> increase and so the dominant features are changed accordingly.</p>
<p>For employee 1 (first observasion), over time is the most important factor to resign. Being a middle-aged man also affect her decision to not resign. Interesting finding is that low total satisfaction contradict the decision for employee 2 to resign. Low number of training time last year and no stock option make him more likely to resign. Employee 3 who has to work over time are more likely to resign that the others, even though being in research development and has more than 3 training time last year <em>suppress</em> his intention to resign.</p>
<p>Apparently, income is not the most important factor for people to turnover. For all 4 employees, over time become the main reason they will likely to resign. Manager may want to reduce the work load of the employees or adopt new work system in order to reduce over time. Another important factor is the stock option available for the employees, suggesting that employees may want to have stock option in the company and perhaps the manager should compensate that.</p>
<h1 id="reference">Reference</h1>
<p>(1) Ribeiro, M. Tulio, Singh, Sameer, and Guestrin, Carlos. 2016. &ldquo;Why Should I Trust You?&quot;: Explaining the Predictions of Any Classifier. <a href="https://arxiv.org/abs/1602.04938">https://arxiv.org/abs/1602.04938</a>
(2) Thomas Lin Pederson. &ldquo;Local Interpretable Model-Agnostic Explanations (R port of original Python package)&quot;. <a href="https://github.com/thomasp85/lime">https://github.com/thomasp85/lime</a>
(3) Brad Boehmke. 2018. &ldquo;LIME: Machine Learning Model Interpretability with LIME&rdquo;. <a href="https://www.business-science.io/business/2018/06/25/lime-local-feature-interpretation.html">https://www.business-science.io/business/2018/06/25/lime-local-feature-interpretation.html</a></p>

  </div>

  <footer>
    <ul class="stats">
  <li class="categories">
    <ul>
        
            
            
                <i class="fa fa-folder"></i>
                
                
                <li><a class="article-category-link" href="/categories/r">R</a></li>
                
            
        
    </ul>
  </li>
  <li class="tags">
    <ul>
        
            
            
                <i class="fa fa-tags"></i>
                
                
                <li><a class="article-category-link" href="/tags/machine-learning">Machine Learning</a></li>
                
                
                <li><a class="article-category-link" href="/tags/capstone-ml">Capstone Ml</a></li>
                
                
                <li><a class="article-category-link" href="/tags/tidymodels">tidymodels</a></li>
                
                
                <li><a class="article-category-link" href="/tags/lime">lime</a></li>
                
            
        
    </ul>
  </li>
</ul>

  </footer>

</article>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-algotech-netlify-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>


<ul class="actions pagination">
    
        <li><a href="/blog/text-lstm/"
                class="button big previous">Text Classification with LSTM</a></li>
    

    
        <li><a href="/blog/bio-intro/"
                class="button big next">Bioinformatics: Decoding Nature&#39;s Code of Life</a></li>
    
</ul>


    </div>
    
<section id="sidebar">

  
  <section id="intro">
    
    
      
        <a href='/'><img src="/img/main/logo.png" class="intro-circle" width="30%" alt="Hugo Future Imperfect" /></a>
      
    
    
      <header>
        <h2>Algoritma Technical Blog</h2>
        <p>We're a group of people who teach data science to individuals, trains companies and their employees to better profit from data. We care about the development of data science and a sense of community that connects our alumni and team with one another. To learn more about our approach to data science problems, feel free to hop over to our blog.</p>
      </header>
    
    
      <ul class="icons">
        
        
  <li><a href="//github.com/teamalgoritma" target="_blank" title="GitHub" class="fa fa-github"></a></li>



























  <li><a href="//linkedin.com/company/teamalgoritma" target="_blank" title="LinkedIn Company" class="fa fa-linkedin"></a></li>









  <li><a href="//facebook.com/teamalgoritma" target="_blank" title="Facebook" class="fa fa-facebook"></a></li>





















  <li><a href="//instagram.com/teamalgoritma" target="_blank" title="Instagram" class="fa fa-instagram"></a></li>





  <li><a href="//twitter.com/teamalgoritma" target="_blank" title="Twitter" class="fa fa-twitter"></a></li>




















      </ul>
    
  </section>



  
  
  

  
  

  
  <section id="footer">
    <p class="copyright">
      
        &copy; 2020
        
          Algoritma Technical Blog
        
      .
      Powered by <a href="//gohugo.io" target="_blank">Hugo</a>
    </p>
  </section>
</section>

    </div>
    <a id="back-to-top" href="#" class="fa fa-arrow-up fa-border fa-2x"></a>
    

    
      
    

    
      
      
      
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>
        
        
        
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/css.min.js"></script>
        <script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>
      
    
    
    
      <script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.js"></script>
      <script src="/js/util.js"></script>
      <script src="/js/main.js"></script>
      <script src="/js/backToTop.js"></script>
    

    
      
        
      
        
          <script src="/js/bootstrap.min.js"></script>
        
      
    

    
    <script>hljs.initHighlightingOnLoad();</script>
      <script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


  </body>
</html>

