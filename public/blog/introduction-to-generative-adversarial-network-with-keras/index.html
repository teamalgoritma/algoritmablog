<!DOCTYPE HTML>

<html>
    <head>
        <script type="application/ld+json">
    {
        "@context" : "http://schema.org",
        "@type" : "BlogPosting",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "\/"
        },
        "articleSection" : "blog",
        "name" : "Introduction to Generative Adversarial Network with Keras",
        "headline" : "Introduction to Generative Adversarial Network with Keras",
        "description" : "In 2018 a paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie\u0026rsquo;s. This made Chritie\u0026rsquo;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?\nIntro  Is artificial intelligence set to become art’s next medium? - Chritie\u0026rsquo;s",
        "inLanguage" : "en",
        "author" : "",
        "creator" : "",
        "publisher": "",
        "accountablePerson" : "",
        "copyrightHolder" : "",
        "copyrightYear" : "2019",
        "datePublished": "2019-12-18 00:00:00 \u002b0000 UTC",
        "dateModified" : "2019-12-18 00:00:00 \u002b0000 UTC",
        "url" : "\/blog\/introduction-to-generative-adversarial-network-with-keras\/",
        "wordCount" : "2100",
        "keywords" : [ "deep learning","Adversarial","Generative Model","Blog" ]
    }
    </script>
        
            
                <title>Introduction to Generative Adversarial Network with Keras</title>
            
        

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="generator" content="Hugo 0.71.1" />
        
  
    
  

  

  <link rel="apple-touch-icon-precomposed" href='/favicon/apple-touch-icon-precomposed.png'>
  <link rel="icon" href='/favicon/favicon.png'>
  
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content='/favicon/mstile.png'>
  <meta name="application-name" content="Algoritma Technical Blog">
  <meta name="msapplication-tooltip" content="To learn more about our approach to data science problems, feel free to hop over to our blog.">
  <meta name="msapplication-config" content='/favicon/ieconfig.xml'>



        
            <meta name="author" content="Iqbal Basyar">
        
        
            
                <meta name="description" content="To learn more about our approach to data science problems, feel free to hop over to our blog.">
            
        

        <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Introduction to Generative Adversarial Network with Keras"/>
<meta name="twitter:description" content="In 2018 a paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie&rsquo;s. This made Chritie&rsquo;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?
Intro  Is artificial intelligence set to become art’s next medium? - Chritie&rsquo;s"/>
<meta name="twitter:site" content="@teamalgoritma"/>

        <meta property="og:title" content="Introduction to Generative Adversarial Network with Keras" />
<meta property="og:description" content="In 2018 a paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie&rsquo;s. This made Chritie&rsquo;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?
Intro  Is artificial intelligence set to become art’s next medium? - Chritie&rsquo;s" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/introduction-to-generative-adversarial-network-with-keras/" />
<meta property="article:published_time" content="2019-12-18T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-12-18T00:00:00+00:00" />

        <meta property="og:image" content="//images/logo.png">
        <meta property="og:image:type" content="image/png">
        <meta property="og:image:width" content="512">
        <meta property="og:image:height" content="512">
        <meta itemprop="name" content="Introduction to Generative Adversarial Network with Keras">
<meta itemprop="description" content="In 2018 a paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie&rsquo;s. This made Chritie&rsquo;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?
Intro  Is artificial intelligence set to become art’s next medium? - Chritie&rsquo;s">
<meta itemprop="datePublished" content="2019-12-18T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-12-18T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="2100">



<meta itemprop="keywords" content="deep learning,Adversarial,Generative Model," />
        

        
            
        

        
        
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">
            <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
            <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.css">
            <link rel="stylesheet" href="/css/main.css">
            <link rel="stylesheet" href="/css/add-on.css">
            <link rel="stylesheet" href="/css/academicons.min.css">
        

        
            
                
            
                
                    <link rel="stylesheet" href="/css/main.css">
                
            
        


  
    
      <link rel="stylesheet" href="/css/night-owl.css" rel="stylesheet" id="theme-stylesheet">
      <script src="/js/highlight.pack.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>
  


      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-164959107-2', 'auto');
	
	ga('send', 'pageview');
}
</script>






    </head>
    <body>

      
      <div id="wrapper">

    
    
<header id="header">
    
      <h1><a href="/">blog</a></h1>
    

    <nav class="links">
        <ul>
            
                <li>
                    <a href="/">
                            <i class="fa fa-home">&nbsp;</i>Home
                    </a>
                </li>
            
                <li>
                    <a href="/tags/machine-learning/">
                            <i class="fa fa-cog">&nbsp;</i>Machine Learning
                    </a>
                </li>
            
                <li>
                    <a href="/tags/data-visualization/">
                            <i class="fa fa-area-chart">&nbsp;</i>Data Visualization
                    </a>
                </li>
            
                <li>
                    <a href="/tags/">
                            <i class="fa fa-list">&nbsp;</i>Article List
                    </a>
                </li>
            
        </ul>
    </nav>
    <nav class="main">
        <ul>
            
            <li id="share-nav" class="share-menu" style="display:none;">
                <a class="fa-share-alt" href="#share-menu">Share</a>
            </li>
            
            <li class="search">
                <a class="fa-search" href="#search">Search</a>
                <form id="search" method="get" action="//google.com/search">
                    <input type="text" name="q" placeholder="Search" />
                    <input type="hidden" name="as_sitesearch" value="/">
                </form>
            </li>
            <li class="menu">
                <a class="fa-bars" href="#menu">Menu</a>
            </li>
        </ul>
    </nav>
</header>


<section id="menu">

    
        <section>
            <form class="search" method="get" action="//google.com/search">
                <input type="text" name="q" placeholder="Search" />
                <input type="hidden" name="as_sitesearch" value="/">
            </form>
        </section>

    
        <section>
            <ul class="links">
                
                    <li>
                        <a href="/">
                            <h3>
                                <i class="fa fa-home">&nbsp;</i>Home
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags/machine-learning/">
                            <h3>
                                <i class="fa fa-cog">&nbsp;</i>Machine Learning
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags/data-visualization/">
                            <h3>
                                <i class="fa fa-area-chart">&nbsp;</i>Data Visualization
                            </h3>
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags/">
                            <h3>
                                <i class="fa fa-list">&nbsp;</i>Article List
                            </h3>
                        </a>
                    </li>
                
            </ul>
        </section>

    
        <section class="recent-posts">
            <div class="mini-posts">
                <header>
                    <h3>Recent Posts</h3>
                </header>
                

                
                    
                

                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/song2vec-music-recommender/">Song2Vec: Music Recommender</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-06-29'>
                                    June 29, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/regression-with-panel-data/">Regression Model with Panel Data</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-06-02'>
                                    June 2, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/pengenalan-teori-antrian/">Pengenalan Teori Antrian</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-04-27'>
                                    April 27, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/stock-cluster/">Clustering Saham Indonesia</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-04-17'>
                                    April 17, 2020</time>
                            </header>
                            

                        </article>
                
                        <article class="mini-post">
                            <header>
                                <h3><a href="/blog/time-and-accuracy-improvement-using-pca/">Time Efficiency and Accuracy Improvement using PCA</a></h3>
                                
                                <time class="published" datetime=
                                    '2020-04-13'>
                                    April 13, 2020</time>
                            </header>
                            

                        </article>
                

                
                    <a href=
                        
                            /blog/
                        
                        class="button">View more posts</a>
                
            </div>
        </section>

    
        
</section>

    <section id="share-menu">
    <section id="social-share-nav">
        <ul class="links">
            <header>
                <h3>Share this post <i class="fa fa-smile-o"></i></h3>
            </header>
            



<li>
  <a href="https://twitter.com/intent/tweet?text=Introduction%20to%20Generative%20Adversarial%20Network%20with%20Keras by Iqbal%20Basyar&amp;url=%2fblog%2fintroduction-to-generative-adversarial-network-with-keras%2f" target="_blank" class="share-btn twitter">
    <i class="fa fa-twitter"></i>
    <p>Twitter</p>
    </a>
</li>








<li>
  <a href="https://www.facebook.com/sharer.php?u=%2fblog%2fintroduction-to-generative-adversarial-network-with-keras%2f" target="_blank" class="share-btn facebook">
    <i class="fa fa-facebook"></i>
    <p>Facebook</p>
    </a>
</li>







<li>
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2fintroduction-to-generative-adversarial-network-with-keras%2f&amp;title=Introduction%20to%20Generative%20Adversarial%20Network%20with%20Keras" target="_blank" class="share-btn linkedin">
      <i class="fa fa-linkedin"></i>
      <p>LinkedIn</p>
    </a>
</li>











        </ul>
    </section>
</section>

    
    <div id="main">
        
        
        <article class="post">
  <header>
    <div class="title">
        
            <h2><a href="/blog/introduction-to-generative-adversarial-network-with-keras/">Introduction to Generative Adversarial Network with Keras</a></h2>
        
        
    </div>
    <div class="meta">
        

        <time class="published"
            datetime='2019-12-18'>
            December 18, 2019</time>
        <span class="author"><a href="https://github.com/iqbalbasyar">Iqbal Basyar</a></span>
        
            <p>10 minute read</p>
        
        
    </div>
</header>


  
    <section id="social-share">
      <ul class="icons">
        



<li>
  <a href="https://twitter.com/intent/tweet?text=Introduction%20to%20Generative%20Adversarial%20Network%20with%20Keras by Iqbal%20Basyar&amp;url=%2fblog%2fintroduction-to-generative-adversarial-network-with-keras%2f" target="_blank" class="share-btn twitter">
    <i class="fa fa-twitter"></i>
    <p>Twitter</p>
    </a>
</li>








<li>
  <a href="https://www.facebook.com/sharer.php?u=%2fblog%2fintroduction-to-generative-adversarial-network-with-keras%2f" target="_blank" class="share-btn facebook">
    <i class="fa fa-facebook"></i>
    <p>Facebook</p>
    </a>
</li>







<li>
  <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fblog%2fintroduction-to-generative-adversarial-network-with-keras%2f&amp;title=Introduction%20to%20Generative%20Adversarial%20Network%20with%20Keras" target="_blank" class="share-btn linkedin">
      <i class="fa fa-linkedin"></i>
      <p>LinkedIn</p>
    </a>
</li>











      </ul>
    </section>
  

  
    

    
        
        







  
  
    
  


        
        
        

        <a href="/blog/introduction-to-generative-adversarial-network-with-keras/" class="image featured">
            <img src="/img/2019/12/banner_gan.jpg" alt="">
        </a>
    


  <div id="content">
    <p>In 2018 a  paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie&rsquo;s. This made Chritie&rsquo;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?</p>
<h1 id="intro">Intro</h1>
<!-- raw HTML omitted -->
<blockquote>
<p>Is artificial intelligence set to become art’s next medium? - Chritie&rsquo;s</p>
</blockquote>
<p>Prerequisites:</p>
<ul>
<li>CNN</li>
<li>Keras</li>
</ul>
<p>As discovered by Ian Goodfellow<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> , GAN is consisted of <strong>two</strong> neural networks named Generator and Discriminator. The Generator was built to create fake images, while the discriminator was built to identify those fake images as fake. Essentially, it&rsquo;s not always have to be fake image. The GAN architecture can build any other type of data like sounds or videos.</p>
<h2 id="course-objective-">Course Objective :</h2>
<ul>
<li>Implement (not optimize) DC-GAN using Keras</li>
</ul>
<h2 id="motivational-examples">Motivational Examples</h2>
<p>Before we go into implementation of GAN, let&rsquo;s see how GAN(s) changes overtime.</p>
<!-- raw HTML omitted -->
<p>Since it&rsquo;s first appearance in 2014, and with the rising of Computer Vision - CNN, GAN grew rapidly. It&rsquo;s now able to generate a stunning images, that even our eyes cannot distinguish whether it&rsquo;s real or fake! Current most state-of-the-art GAN are StyleGAN, and you can check it&rsquo;s result in <a href="thispersondoesntexist.com">thispersondoesntexist.com</a>. Let&rsquo;s see several types of GANs</p>
<h3 id="cgan-conditional-gan-2014">CGAN (Conditional GAN, 2014)</h3>
<!-- raw HTML omitted -->
<p>GAN was originally created to be trainable with only <strong>ONE</strong> class. If you train your GAN with dog images, it can generate dog images. If you train your GAN with cat images, it can generate cat images. But, what if your GAN was trained into both cat and dog images ? It will generate a blurry animal. To overcome this, Mirza<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> created CGAN that can diffrentiate multiple output.</p>
<p>This work also make it possible to guide an image into something else like example below</p>
<!-- raw HTML omitted -->
<p><!-- raw HTML omitted --><em>source: <a href="https://papers.nips.cc/paper/6644-pose-guided-person-image-generation.pdf">https://papers.nips.cc/paper/6644-pose-guided-person-image-generation.pdf</a></em><!-- raw HTML omitted --></p>
<h3 id="cyclegan-2018">CycleGAN, 2018</h3>
<p>In 2018, Zu<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> create a CycleGAN, A GAN that <strong>Doesn&rsquo;t Generate Fake Images</strong>. Instead, it transfer styles between images.</p>
<p>Have you ever imagine a horse with zebra lines ?</p>
<!-- raw HTML omitted -->
<p>Or, playing Fortnite with PUBG style?</p>
<!-- raw HTML omitted -->
<p>Unlike <a href="https://towardsdatascience.com/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461">Style Transfer</a>, cycle gan is not limited by domain, wich means, you can do text-to-image style transfer!</p>
<!-- raw HTML omitted -->
<p><!-- raw HTML omitted -->Sources: <a href="https://junyanz.github.io/CycleGAN/">Zebra-Horse</a>,<a href="https://towardsdatascience.com/turning-fortnite-into-pubg-with-deep-learning-cyclegan-2f9d339dcdb0">Fortnite-PUBG</a>, <a href="https://arxiv.org/pdf/1808.04538.pdf">text-image</a> 
<!-- raw HTML omitted --></p>
<h3 id="sagan-self-attention-gan-2018">SAGAN (Self Attention GAN, 2018)</h3>
<p>After Computer Vision takes over ML&rsquo;s attentions for years, eventually it face a saturation phase, where it&rsquo;s considered as State-of-the-art model for Image Classifiation, Detection, Segmentations, etc. There&rsquo;s nothing such a new architecture, everything is CNN. That&rsquo;s when NLP kicks in. Thanks for <a href="https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/">Transformers</a>, NLP started to find a new hope, and generated a model called <a href="https://medium.com/@joealato/attention-in-nlp-734c6fa9d983">Attention</a>. This idea then inspired Zhang<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> to create a Self Attention GAN that can help them focus on the context of the images. His model then considered as the state-of-the art GAN. But not for a long time.</p>
<!-- raw HTML omitted -->
<h3 id="progan-2018">ProGAN (2018)</h3>
<p>Training GAN is hard. Knowing that the Generator and Discriminator fighting each other, GAN losses somethimes become unstable and can jumped just after the model started to look converge.</p>
<!-- raw HTML omitted -->
<p><!-- raw HTML omitted -->Source: <a href="https://cdn-images-1.medium.com/max/1600/1*tUhgr3m54Qc80GU2BkaOiQ.gif">Medium</a>
<!-- raw HTML omitted --></p>
<p>In order to face that, Karras<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> and his mates from NVIDIA started to build a GAN that gradually increasing it&rsquo;s size in order to maintain training stability. This method get a lot of compliment as it nominated as state-of-the-art.</p>
<h3 id="biggan-2019">BigGAN (2019)</h3>
<p>In 2019, Brock<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> and his teammates from Google Deepmind attempted to create a GAN that run on a large scale of TPU cluster. Hence the name, BigGAN. No one have ever tried to train GAN on such a large cluster of machine. Now you know the power of Google.</p>
<!-- raw HTML omitted -->
<p><!-- raw HTML omitted -->Source: Brock&rsquo;s Paper
<!-- raw HTML omitted --></p>
<p>Despite it&rsquo;s kind of meaningless name, this model really, really, made an improvement of GAN. It can generate very realistic images in large dimension (512x512). It&rsquo;s inception score also killed the previous state-of-the art models from 52.52 into 166.5.</p>
<h3 id="stylegan">StyleGAN</h3>
<p>GANs already reach its point wich it can generate a hyper-realistic images. But GAN it&rsquo;s such a meaningless if we can&rsquo;t generate another object from it. 
Still from NVIDIA instead of continue creating more realistic images, Karras<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> focused on making GAN that can be controlled over a style, hence the name StyleGAN. This mean you have big control of what image will you generate. Or more likely, How do you want the image to be.</p>
<!-- raw HTML omitted -->
<p><!-- raw HTML omitted -->Source: Karras&rsquo;s Paper
<!-- raw HTML omitted --></p>
<p><a href="https://www.youtube.com/watch?v=kSLJriaOumA">This video</a> from StyleGAN&rsquo;s creator might help you understand how it works.</p>
<p>If you want to know more about GANs, there&rsquo;s a repository contains all(I really hope it is) paper that related to GAN
<a href="https://github.com/hindupuravinash/the-gan-zoo">https://github.com/hindupuravinash/the-gan-zoo</a></p>
<p>I think that&rsquo;s enough of some motivational intro. Now, let&rsquo;s build our GAN. In this case, DC-GAN.</p>
<h1 id="implementation">Implementation</h1>
<p>For the sake of easness, we will be using MNIST dataset that already brought by Keras. Let&rsquo;s first import our library</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

<span style="color:#f92672">from</span> tensorflow.keras.models <span style="color:#f92672">import</span> Sequential, load_model
<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Dense, Conv2D, Flatten, BatchNormalization, Dropout
<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Reshape, UpSampling2D, MaxPooling2D, Activation
<span style="color:#f92672">from</span> tensorflow.keras.datasets <span style="color:#f92672">import</span> mnist, fashion_mnist
<span style="color:#f92672">from</span> tensorflow.keras.optimizers <span style="color:#f92672">import</span> SGD, RMSprop
<span style="color:#f92672">from</span> tensorflow.keras.utils <span style="color:#f92672">import</span> to_categorical

<span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</code></pre></div><p>After all the libary are imported, let&rsquo;s load our data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">(X_train, y_train), (X_test, y_test) <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>load_data()
<span style="color:#75715e">#(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()</span>

X_train <span style="color:#f92672">=</span> (X_train<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32) <span style="color:#f92672">-</span> <span style="color:#ae81ff">127.5</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">127.5</span> <span style="color:#75715e"># normalization</span>
X_train <span style="color:#f92672">=</span> X_train[:, :, :, None]
X_test <span style="color:#f92672">=</span> X_test[:, :, :, None]
</code></pre></div><p>The Mnist images are 28x28x1 grayscale of handwritten digits. It contains 60000 set of train data and 10000 set of test data. If you haven&rsquo;t seen it before, here&rsquo;s what they looks like</p>
<!-- raw HTML omitted -->
<h2 id="gan-basic-concept">Gan Basic Concept</h2>
<p>GAN is consisted of Generator and Discriminator. In DC-GAN, the Generator and Discriminator are convolutional neural network. Let&rsquo;s build a simple Generator and Discriminator, then combine them and finally train them.</p>
<h2 id="helper-functions">Helper Functions</h2>
<p>Some of you might not familiar in practicing with keras, especially building a non-API-ed models such as GAN. Building GAN (and other Deep Learning architecture as well) is like building a lego block. You build them piece-by-piece.</p>
<blockquote>
<p>There should be one—and preferably only one—obvious way to do it</p>
</blockquote>
<p>So, in order to help you build the GAN, We prepared several helpful function. You are not obligated to understand the codes, but We hope that you can figured out the big picture.</p>
<h4 id="combine-images">Combine Images</h4>
<p>This function will arrange several images into one frame so that it will be easier to see. This is the sample result:</p>
<!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">combine_images</span>(generated_images):
    num <span style="color:#f92672">=</span> generated_images<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
    width <span style="color:#f92672">=</span> int(np<span style="color:#f92672">.</span>sqrt(num))
    height <span style="color:#f92672">=</span> int(np<span style="color:#f92672">.</span>ceil(float(num)<span style="color:#f92672">/</span>width))
    shape <span style="color:#f92672">=</span> generated_images<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">3</span>]
    image <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((height<span style="color:#f92672">*</span>shape[<span style="color:#ae81ff">0</span>], width<span style="color:#f92672">*</span>shape[<span style="color:#ae81ff">1</span>]),
                     dtype<span style="color:#f92672">=</span>generated_images<span style="color:#f92672">.</span>dtype)
    <span style="color:#66d9ef">for</span> index, img <span style="color:#f92672">in</span> enumerate(generated_images):
        i <span style="color:#f92672">=</span> int(index<span style="color:#f92672">/</span>width)
        j <span style="color:#f92672">=</span> index <span style="color:#f92672">%</span> width
        image[i<span style="color:#f92672">*</span>shape[<span style="color:#ae81ff">0</span>]:(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>shape[<span style="color:#ae81ff">0</span>], j<span style="color:#f92672">*</span>shape[<span style="color:#ae81ff">1</span>]:(j<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>shape[<span style="color:#ae81ff">1</span>]] <span style="color:#f92672">=</span> \
            img[:, :, <span style="color:#ae81ff">0</span>]
    <span style="color:#66d9ef">return</span> image
</code></pre></div><h4 id="generate-generator">Generate Generator</h4>
<p>Generator are made of several layers. The key idea is to :</p>
<ol>
<li>Get input vector (often called &ldquo;z&rdquo;)</li>
<li>Feature Mapping using Dense</li>
<li>Reshape the vector into 2D</li>
<li>Do convolutions</li>
<li>Do uppersamplings</li>
<li>Output the Images</li>
</ol>
<p>Process number 3-4 are often called &ldquo;transpose convolutions&rdquo; or &ldquo;deconvolutions&rdquo;. 
Please note that you can build your own Generator architecture.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generator_model</span>():
    model <span style="color:#f92672">=</span> Sequential([
        Dense(<span style="color:#ae81ff">1024</span>, input_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>),
        Dense(<span style="color:#ae81ff">128</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span>), <span style="color:#75715e"># This shape related to the reshape and output size</span>
        BatchNormalization(),
        Activation(<span style="color:#e6db74">&#39;tanh&#39;</span>),
        Reshape((<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">128</span>)),
        UpSampling2D(size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)),
        Conv2D(<span style="color:#ae81ff">64</span>, (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>),
        UpSampling2D(size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)),
        Conv2D(<span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>)
    ])
    <span style="color:#66d9ef">return</span> model

generator_model()<span style="color:#f92672">.</span>summary()
</code></pre></div><h3 id="discriminator">Discriminator</h3>
<p>The Discriminator in GAN is basically a normal CNN that has to be trained to classify fake or real images. It supposed to work as :</p>
<ol>
<li>Get input image (the fake one, built by Generator)</li>
<li>Do Convolutions</li>
<li>Do subsamplings (or poolings)</li>
<li>Reshape to 1D</li>
<li>Classify using Dense</li>
<li>Output the classification</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">discriminator_model</span>():
    model <span style="color:#f92672">=</span> Sequential([
        Conv2D(<span style="color:#ae81ff">64</span>, (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>), input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>),
        MaxPooling2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)),
        Conv2D(<span style="color:#ae81ff">128</span>, (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>),activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>),
        MaxPooling2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)),
        Flatten(),
        Dense(<span style="color:#ae81ff">1024</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>),
        Dense(<span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sigmoid&#39;</span>)
    ])
    <span style="color:#66d9ef">return</span> model

discriminator_model()<span style="color:#f92672">.</span>summary()
</code></pre></div><h3 id="combining-generator--discriminator">Combining Generator + Discriminator</h3>
<p>Now that we previously can create Generator and Discriminator, this function is merely combine both of them into one sequential. Generator first, followed by discriminator.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">combine_model</span>(g, d):
    model <span style="color:#f92672">=</span> Sequential()
    model<span style="color:#f92672">.</span>add(g)
    model<span style="color:#f92672">.</span>add(d)
    <span style="color:#66d9ef">return</span> model
</code></pre></div><p>But it&rsquo;s not over yet. The model is not ready for training. It must be compiled first. And to compile, we need several hyperparameters in order for them to train well :</p>
<ul>
<li>optimizer (with learning rate)</li>
<li>loss function</li>
</ul>
<p>So, let&rsquo;s add the hyperparameters in training functions below.</p>
<h3 id="training-function">Training Function</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_gan</span>(X_train, Y_train, batch_size, epochs, g, d, save_every<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>, print_every<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
    
    <span style="color:#75715e"># Get the size of input (Z vector)</span>
    z_size <span style="color:#f92672">=</span> g<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>input_shape[<span style="color:#ae81ff">1</span>]
    
    <span style="color:#75715e"># Combine discriminator on generator</span>
    d<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> False <span style="color:#75715e"># set Discriminator to be untrainable before merging</span>
    d_on_g <span style="color:#f92672">=</span> combine_model(g, d)    
    dg_optim <span style="color:#f92672">=</span> RMSprop (lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0005</span>)
    g_optim <span style="color:#f92672">=</span> RMSprop (lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0005</span>)
    d_on_g<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>dg_optim)
    
    g<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>g_optim)
    
    <span style="color:#75715e"># Set Discriminator to be trainable </span>
    d<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> True
    d_optim <span style="color:#f92672">=</span> RMSprop (lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0005</span>)
    d<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>d_optim)
    
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Number of batches&#34;</span>, int(X_train<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">/</span>batch_size))
    
    <span style="color:#75715e"># Start training</span>
    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">-------------------------------</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Epoch :&#34;</span>, epoch)        
        
        <span style="color:#66d9ef">for</span> index <span style="color:#f92672">in</span> range(int(X_train<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">/</span>batch_size)):
            
            <span style="color:#75715e"># Randomly generate Z input</span>
            noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, size<span style="color:#f92672">=</span>(batch_size, z_size))
            
            <span style="color:#75715e"># Generate fake image from Z </span>
            generated_images <span style="color:#f92672">=</span> g<span style="color:#f92672">.</span>predict(noise, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
            
            <span style="color:#75715e"># Take train data (real image)</span>
            image_batch <span style="color:#f92672">=</span> X_train[index<span style="color:#f92672">*</span>batch_size:(index<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>batch_size]
            
            <span style="color:#66d9ef">if</span> index <span style="color:#f92672">%</span> save_every <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
                image <span style="color:#f92672">=</span> combine_images(generated_images)
                image <span style="color:#f92672">=</span> image<span style="color:#f92672">*</span><span style="color:#ae81ff">127.5</span><span style="color:#f92672">+</span><span style="color:#ae81ff">127.5</span>
                <span style="color:#75715e"># Image.fromarray(image.astype(np.uint8)).save(&#34;train_ep&#34;+</span>
                <span style="color:#75715e">#     str(epoch)+&#34;_&#34;+str(index)+&#34;.png&#34;)</span>
                
                plt<span style="color:#f92672">.</span>imshow(image, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>get_cmap(<span style="color:#e6db74">&#39;gray&#39;</span>))
                plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
                plt<span style="color:#f92672">.</span>show()
                
            <span style="color:#75715e"># Concatenate images to train Discriminator</span>
            X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate((image_batch, generated_images))
            y <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>] <span style="color:#f92672">*</span> batch_size <span style="color:#f92672">+</span> [<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> batch_size
            
            <span style="color:#75715e"># Train Discriminator</span>
            d_loss <span style="color:#f92672">=</span> d<span style="color:#f92672">.</span>train_on_batch(X, y)           
            
            <span style="color:#75715e"># Randomly generate z to train Generator</span>
            noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, (batch_size, z_size))
            
            <span style="color:#75715e"># Set Discriminator to be untrainable before training the GAN (for generator)</span>
            d<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> False            
            
            <span style="color:#75715e"># Train GAN (for the generator)</span>
            g_loss <span style="color:#f92672">=</span> d_on_g<span style="color:#f92672">.</span>train_on_batch(noise, [<span style="color:#ae81ff">1</span>] <span style="color:#f92672">*</span> batch_size)
            
            <span style="color:#75715e"># Print loss</span>
            <span style="color:#66d9ef">if</span> index <span style="color:#f92672">%</span> print_every <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>: 
                <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;batch </span><span style="color:#e6db74">%d</span><span style="color:#e6db74">, g_loss : </span><span style="color:#e6db74">%f</span><span style="color:#e6db74">, d_loss : </span><span style="color:#e6db74">%f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (index, g_loss, d_loss))
            
            <span style="color:#75715e"># Set Discriminator to be trainable</span>
            d<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> True       
            
        
    <span style="color:#66d9ef">return</span> g, d
</code></pre></div><p>If you think that it&rsquo;s hard to understand those code, don&rsquo;t worry. Now let&rsquo;s move to the main part.</p>
<h2 id="lets-build-our-gan">Let&rsquo;s build our GAN</h2>
<h3 id="initialize-model">Initialize Model</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">z_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
g_model <span style="color:#f92672">=</span> generator_model()
d_model <span style="color:#f92672">=</span> discriminator_model()
</code></pre></div><h3 id="train-gan">Train GAN</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">batch <span style="color:#f92672">=</span> <span style="color:#ae81ff">225</span>
epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
g_model, d_model <span style="color:#f92672">=</span> train_gan(X_train,y_train, batch, epochs, g_model, d_model)
</code></pre></div><p>Here&rsquo;s how our model fake images after trained for each epoch</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="generate-images">Generate Images</h3>
<p>Now that our model have the understanding of how to draw an mnist image, let&rsquo;s try to generate one.</p>
<h4 id="generate-image-only-from-generator">Generate image only from generator</h4>
<p>As we trained our GAN, we trained our Generator to generate fake images (in this case, handwritten digits). So, given an input of random z vector, our Generator is supposed to generate a handwritted images. Let&rsquo;s try make 100 of it!</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_images</span>(g, batch_size):
    z_size <span style="color:#f92672">=</span> g<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>input_shape[<span style="color:#ae81ff">1</span>]
    noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, (batch_size, z_size))
    generated_images <span style="color:#f92672">=</span> g<span style="color:#f92672">.</span>predict(noise, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    image <span style="color:#f92672">=</span> combine_images(generated_images)
    filename <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;generated_image.png&#34;</span>
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">*</span><span style="color:#ae81ff">127.5</span><span style="color:#f92672">+</span><span style="color:#ae81ff">127.5</span>
    Image<span style="color:#f92672">.</span>fromarray(image<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>uint8))<span style="color:#f92672">.</span>save(filename)
    <span style="color:#66d9ef">return</span> image

images <span style="color:#f92672">=</span> generate_images(g_model, <span style="color:#ae81ff">100</span>)
plt<span style="color:#f92672">.</span>imshow(images, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>get_cmap(<span style="color:#e6db74">&#39;gray&#39;</span>))
plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><!-- raw HTML omitted -->
<h4 id="generate-images-from-generator-with-discriminator-check">Generate images from generator with discriminator check</h4>
<p>Basically our Generator is capable enough to do the job. But is there any possible way to make the generated images looks more realistic?. You&rsquo;re right ! Pass them to the Discriminator. Previously, our Discriminator has the capability to classify fake images. So, let&rsquo;s use it as QA agent. If our fake image is classified as real, then, by concept, it should be more realistic than images that clasified as fake. Without furder ado, let&rsquo;s try it !</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_best_images</span>(g, d, batch_size):
    z_size <span style="color:#f92672">=</span> g<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>input_shape[<span style="color:#ae81ff">1</span>]
    noise <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, (batch_size<span style="color:#f92672">*</span><span style="color:#ae81ff">20</span>, z_size))

    generated_images <span style="color:#f92672">=</span> g<span style="color:#f92672">.</span>predict(noise, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    d_pret <span style="color:#f92672">=</span> d<span style="color:#f92672">.</span>predict(generated_images, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

    index <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, batch_size<span style="color:#f92672">*</span><span style="color:#ae81ff">20</span>)
    index<span style="color:#f92672">.</span>resize((batch_size<span style="color:#f92672">*</span><span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">1</span>))

    pre_with_index <span style="color:#f92672">=</span> list(np<span style="color:#f92672">.</span>append(d_pret, index, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
    pre_with_index<span style="color:#f92672">.</span>sort(key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">0</span>], reverse<span style="color:#f92672">=</span>True)

    nice_images <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((batch_size,) <span style="color:#f92672">+</span> generated_images<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">3</span>], dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
    nice_images <span style="color:#f92672">=</span> nice_images[:, :, :, None]

    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(batch_size):
        idx <span style="color:#f92672">=</span> int(pre_with_index[i][<span style="color:#ae81ff">1</span>])
        nice_images[i, :, :, <span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> generated_images[idx, :, :, <span style="color:#ae81ff">0</span>]

    image <span style="color:#f92672">=</span> combine_images(nice_images)
    filename <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;generated_image_best.png&#34;</span>
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">*</span><span style="color:#ae81ff">127.5</span><span style="color:#f92672">+</span><span style="color:#ae81ff">127.5</span>
    Image<span style="color:#f92672">.</span>fromarray(image<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>uint8))<span style="color:#f92672">.</span>save(filename)
    <span style="color:#66d9ef">return</span> image

images <span style="color:#f92672">=</span> generate_best_images(g_model, d_model, <span style="color:#ae81ff">100</span>)
plt<span style="color:#f92672">.</span>imshow(images, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>get_cmap(<span style="color:#e6db74">&#39;gray&#39;</span>))
plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><!-- raw HTML omitted -->
<p>Congratulations! you now can generate realistic handwritten images using Generator and Discriminator simultaneuosly. What? you want to generate specific number?</p>
<h2 id="latent-vector-operations">Latent Vector Operations</h2>
<p>It was found that the z vector of specific class tends to have a similarity. It&rsquo;s later said that for a specific class, there should be a vector z that represent it. Now it&rsquo;s called Latent Vector. So, in order to create image of number &ldquo;1&rdquo;, you can easily do an average of z vector that generates &ldquo;1&rdquo;, use it as input of Generator, and Voila ! You will create a number &ldquo;1&rdquo; (conceptually).</p>
<h2 id="refereces">Refereces:</h2>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://arxiv.org/pdf/1406.2661.pdf">Goodfellow, Ian J. - Generative Adversarial Nets, 2014</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1411.1784">Mirza, M. -  Conditional Generative Adversarial Nets, 2014</a> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1703.10593v6">Zhu, JY. et al - Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, 2018</a> <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1805.08318v1">Zhang, Han - Self-Attention Generative Adversarial Network. 2018</a> <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1710.10196">Karras, Tero- Progressive Growing of GANs for Improved Quality Stability and Variation, 2018</a> <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1809.11096v2">Brock, Andrew - Large Scale GAN Training for High Fidelity Natural Image Synthesis, 2019</a> <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1812.04948">Karras, Tero - A Style-Based Generator Architecture for Generative Adversarial Networks, 2019</a> <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

  </div>

  <footer>
    <ul class="stats">
  <li class="categories">
    <ul>
        
            
            
                <i class="fa fa-folder"></i>
                
                
                <li><a class="article-category-link" href="/categories/python">Python</a></li>
                
            
        
    </ul>
  </li>
  <li class="tags">
    <ul>
        
            
            
                <i class="fa fa-tags"></i>
                
                
                <li><a class="article-category-link" href="/tags/deep-learning">deep learning</a></li>
                
                
                <li><a class="article-category-link" href="/tags/adversarial">Adversarial</a></li>
                
                
                <li><a class="article-category-link" href="/tags/generative-model">Generative Model</a></li>
                
            
        
    </ul>
  </li>
</ul>

  </footer>

</article>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-algotech-netlify-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>


<ul class="actions pagination">
    
        <li><a href="/blog/ridge-lasso/"
                class="button big previous">Ridge and LASSO Regression</a></li>
    

    
        <li><a href="/blog/optimization-with-genetic-algorithm/"
                class="button big next">Optimization and Hyper-Parameter Tuning with Genetic Algorithm</a></li>
    
</ul>


    </div>
    
<section id="sidebar">

  
  <section id="intro">
    
    
      
        <a href='/'><img src="/img/main/logo.png" class="intro-circle" width="30%" alt="Hugo Future Imperfect" /></a>
      
    
    
      <header>
        <h2>Algoritma Technical Blog</h2>
        <p>We're a group of people who teach data science to individuals, trains companies and their employees to better profit from data. We care about the development of data science and a sense of community that connects our alumni and team with one another. To learn more about our approach to data science problems, feel free to hop over to our blog.</p>
      </header>
    
    
      <ul class="icons">
        
        
  <li><a href="//github.com/teamalgoritma" target="_blank" title="GitHub" class="fa fa-github"></a></li>



























  <li><a href="//linkedin.com/company/teamalgoritma" target="_blank" title="LinkedIn Company" class="fa fa-linkedin"></a></li>









  <li><a href="//facebook.com/teamalgoritma" target="_blank" title="Facebook" class="fa fa-facebook"></a></li>





















  <li><a href="//instagram.com/teamalgoritma" target="_blank" title="Instagram" class="fa fa-instagram"></a></li>





  <li><a href="//twitter.com/teamalgoritma" target="_blank" title="Twitter" class="fa fa-twitter"></a></li>




















      </ul>
    
  </section>



  
  
  

  
  

  
  <section id="footer">
    <p class="copyright">
      
        &copy; 2020
        
          Algoritma Technical Blog
        
      .
      Powered by <a href="//gohugo.io" target="_blank">Hugo</a>
    </p>
  </section>
</section>

    </div>
    <a id="back-to-top" href="#" class="fa fa-arrow-up fa-border fa-2x"></a>
    <style>
      .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        height:50px; 
        background-color: black;
        color: white;
        text-align: center;
        padding-top: 15px;
        padding-bottom: 15px;
        padding-left: 50px;
        padding-right: 50px;
}
      }


      </style>

      <div class="footer">
        <p>
          Want to know more about our workshop?
          <a href="https://algorit.ma/?utm_source=algotech&utm_medium=content&utm_campaign=introduction-to-generative-adversarial-network-with-keras" style="color: rgb(197, 38, 38)"> Visit our main website here</a> <br>
        </p>
          
      </div>
    

    
      
    

    
      
      
      
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>
        
        
        
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
        <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/css.min.js"></script>
        <script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>
      
    
    
    
      <script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.js"></script>
      <script src="/js/util.js"></script>
      <script src="/js/main.js"></script>
      <script src="/js/backToTop.js"></script>
    

    
      
        
      
        
          <script src="/js/bootstrap.min.js"></script>
        
      
    

    
    <script>hljs.initHighlightingOnLoad();</script>
      <script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


  </body>
</html>

