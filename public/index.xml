<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algoritma Technical Blog</title>
    <link>/</link>
    <description>Recent content on Algoritma Technical Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Oct 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Rplicate Series: Cherry Bomb</title>
      <link>/blog/rplicate-series-cherry-bomb/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/rplicate-series-cherry-bomb/</guid>
      <description>In this second article on Rplicate Series, We will share to you one way to replicate the plot titled Cherry Bomb from the article &amp;ldquo;Japan’s cherry blossoms are emerging increasingly early, 7th April 2017&amp;rdquo;. The raw dataset used for this graph was obtained from a phenological dataset that was previously collected by Dr. Yasuyuki Aono from Osaka Prefecture University12.
 {width=&amp;ldquo;60%&amp;rdquo;} 
While replicating the plot, we will also learn how to:</description>
    </item>
    
    <item>
      <title>Skincare Recommendation System</title>
      <link>/blog/skincare-recommender-system/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/skincare-recommender-system/</guid>
      <description>body {text-align: justify}Have you ever imagine how Netflix give you recommendation for movies you have never watch before?If you’re familiar with machine learning, you can find the answer. Yappps.. that’s right. The answer is “Recommendation System”.Recommendation system or recommender system is subclass of information filtering system that seeks to predict the “rating” or “preference” a user would give to an item. Recommendation system aims to telling us which movies to watch (Netflix), which product to buy (Amazone), or which songs to listen (Spotify) based on our historical data.</description>
    </item>
    
    <item>
      <title>Rplicate Series: Happiness of The Third Age</title>
      <link>/blog/rplicate-happiness-of-the-third-age/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/rplicate-happiness-of-the-third-age/</guid>
      <description>Have you ever wonder how far ggplot2 and other packages in R can go for data visualization? Here, we are introducing the Rplicate Series: a series of articles for data visualization in R using ggplot2 and other packages, in aim to replicate The Economist plot. The Economist is an international weekly newspaper that focuses on current affairs, international business, politics, and technology. Along with its article, various graphs were displayed with visuals that is captivating to the eye.</description>
    </item>
    
    <item>
      <title>Song2Vec: Music Recommender</title>
      <link>/blog/song2vec-music-recommender/</link>
      <pubDate>Mon, 29 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/song2vec-music-recommender/</guid>
      <description>body {text-align: justify}BackgroundThe behavior of musicophiles has changed along with the evolvement of the music industry in the past decades. Previously we conservatively bought music on a compact disc, but now music streaming services are more preferable; such as Amazon Music,Apple Music, Google Play Music, Pandora, Spotify, Youtube Music, to name a few. This is because of the convenience offered by these platforms so that users are able to search their favorite songs right away without having to bother going to the music store physically.</description>
    </item>
    
    <item>
      <title>Regression Model with Panel Data</title>
      <link>/blog/regression-with-panel-data/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/regression-with-panel-data/</guid>
      <description>body {text-align: justify}IntroductionPanel RegressionPanel data are also called longitudinal data or cross-sectional time-series data. A panel data set has multiple entities, each of which has repeated measurements at different time periods. Panel data may have individual (group) effect, time effect, or both, which are analyzed by fixed effect and/or random effect models.1
Panel data examples:
Annual unemployment rates of each state over several years</description>
    </item>
    
    <item>
      <title>Pengenalan Teori Antrian</title>
      <link>/blog/pengenalan-teori-antrian/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/pengenalan-teori-antrian/</guid>
      <description>body { text-align: justify}  Introduction &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Apakah kamu pernah melihat antrian dalam aktivitas sehari-hari? Pasti kamu pernah melihat banyak sekali kejadian dimana pelanggan menunggu dan membentuk suatu antrian yang panjang untuk dilayani oleh server. Kita tentunya pernah melihat antrian pelanggan yang menunggu untuk dilayani di bank, antrian untuk membeli makanan di restoran, antrian untuk masuk lift, antrian untuk mendapatkan resep obat di rumah sakit, dan masih banyak lagi.</description>
    </item>
    
    <item>
      <title>Clustering Saham Indonesia</title>
      <link>/blog/stock-cluster/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/stock-cluster/</guid>
      <description>body {text-align: justify}IntroductionSaham merupakan satuan nilai atau pembukuan dalam berbagai instrumen finansial yang mengacu pada bagian kepemilikan sebuah perusahaan. Perusahaan yang dapat menjual sahamnya ke publik merupakan saham yang sudah listing di bursa atau sudah melakukan Initial Public Offering (IPO)1. Terdapat sekitar 680 saham per Maret 2020 yang sudah listing di bursa efek Indonesia dan jumlahnya terus bertambah seiring berjalannya waktu. Setiap saham yang melantai dibursa memiliki karakteristik yang berbeda beda baik dari sisi fundamental perusahaan maupun pergerakan harga sahamnya dibursa (teknikal), oleh sebab itu perlu dilakukan pengelompokkan emiten berdasarkan karakteristik dari saham itu sendiri.</description>
    </item>
    
    <item>
      <title>Time Efficiency and Accuracy Improvement using PCA</title>
      <link>/blog/time-and-accuracy-improvement-using-pca/</link>
      <pubDate>Mon, 13 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/time-and-accuracy-improvement-using-pca/</guid>
      <description>About Dimensionality ReductionIf you are familiar enough with data, sometimes you are faced with too many predictor variables that make the computation so heavy. Let us say, you are challenged to predict employee in your company will resign or not while the variables are the level of satisfaction on work, number of project, average monthly hours, time spend at the company, etc. You are facing so many predictor that took so long for training your model.</description>
    </item>
    
    <item>
      <title>Text Generation with Markov Chains</title>
      <link>/blog/text-generating-with-markov-chains/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-generating-with-markov-chains/</guid>
      <description>body {text-align: justify}IntroductionText GenerationNatural Language Processing (NLP) is a branch of artificial intelligence that is steadily growing both in terms of research and market values1. The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable2. The are many applications of NLP in various industries, such as:
SPAM email detectionSentiment AnalysisText summarizationTopic ModellingText GenerationIn this article, we will try to learn the last one: text generation.</description>
    </item>
    
    <item>
      <title>Interpreting Text Classification Model with LIME</title>
      <link>/blog/text-lime/</link>
      <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-lime/</guid>
      <description>body {text-align: justify}IntroductionThis article will focus on the implementation of LIME for interpreting text classification, since they are slightly different from common classification problem. We will cover the important points as clearly as possible. More detailed concept of LIME is available at my previous post .
One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target?</description>
    </item>
    
    <item>
      <title>DBSCAN Clustering</title>
      <link>/blog/dbscan-clustering/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/dbscan-clustering/</guid>
      <description>body {text-align: justify}1. Pendahuluan1.1 Clustering Clustering merupakan salah satu bagian dari unsupervised learning. Clustering memiliki tujuan untuk membagi data ke dalam beberapa kelompok berdasarkan kemiripan antar data. Cluster (kelompok) yang baik adalah cluster yang memiliki kemiripan yang besar antar anggota clusternya dan memiliki perbedaan yang signifikan dengan anggota cluster yang berbeda. Clustering dapat diterapkan dalam berbagai bidang seperti segmentasi pasar, cluster profiling, data spatial dll.</description>
    </item>
    
    <item>
      <title>Optimization and Hyper-Parameter Tuning with Genetic Algorithm</title>
      <link>/blog/optimization-with-genetic-algorithm/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/optimization-with-genetic-algorithm/</guid>
      <description>IntroductionAboutOptimization is important in many fields, including in data science. In manufacturing, where every decision is critical to the process and the profit of organization, optimization is often employed, from the number of each products produced, how the unit is scheduled for production, get the best or optimal process parameter, and also the routing determination such as the traveling salesman problem. In data science, we are familiar with model tuning, where we tune our model in order to improve the model performance.</description>
    </item>
    
    <item>
      <title>Introduction to Generative Adversarial Network with Keras</title>
      <link>/blog/introduction-to-generative-adversarial-network-with-keras/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/introduction-to-generative-adversarial-network-with-keras/</guid>
      <description>In 2018 a paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie&amp;rsquo;s. This made Chritie&amp;rsquo;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?
Intro  
 Is artificial intelligence set to become art’s next medium?</description>
    </item>
    
    <item>
      <title>Ridge and LASSO Regression</title>
      <link>/blog/ridge-lasso/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/ridge-lasso/</guid>
      <description>Overview Regression analysis is a way that can be used to determine the relationship between the predictor variable (x) and the target variable (y).
Ordinary Least Squares (OLS) is the most common estimation method for linear models and it applies for good reasons. As long as your model meets the OLS assumptions for linear regression, you can rest easy knowing that you get the best estimate.
But in the real world to meet OLS regression assumptions will be very difficult.</description>
    </item>
    
    <item>
      <title>Bioinformatics: Decoding Nature&#39;s Code of Life</title>
      <link>/blog/bio-intro/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/bio-intro/</guid>
      <description>It is inarguable that Data Science gives a tremendous impact on today&amp;rsquo;s industry. Furthermore, it also accelerates the development of basic science research including Biology. Biology harbors some of the most intriguing ideas we may find today; from finding cures for genetic diseases, to something far as breeding mutants! This article will guide you through the wondrous journey of when Data Science meets Biology and how it can impact our life.</description>
    </item>
    
    <item>
      <title>Interpreting Classification Model with LIME</title>
      <link>/blog/interpreting-classification-model-with-lime/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/interpreting-classification-model-with-lime/</guid>
      <description>Introduction One of many things to consider when we want to choose a machine learning model is the interpretability: can we analyze what variables or certain values that contribute toward particular class or target? Some models can be easily interpreted, such as the linear or logistic regression model and decision trees, but interpreting more complex model such as random forest and neural network can be challenging. This sometimes drive the data scientist to choose more interpretable model since they need to communicate it to their manager or higher rank, who perhaps are not familiar with machine learning.</description>
    </item>
    
    <item>
      <title>Text Classification with LSTM</title>
      <link>/blog/text-lstm/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-lstm/</guid>
      <description>Deep Neural Network Before we further discuss the Long Short-Term Memory Model, we will first discuss the term of Deep learning where the main idea is on the Neural Network. So Neural Network is one branch of machine learning where the learning process imitates the way neurons in the human brain works. In Neural Network we know several terms, such as the input layer, hidden layer, and output layer. So the different betweetn Deep Learning and Neural Network architecture is the number of hidden layers specified.</description>
    </item>
    
    <item>
      <title>Poisson Regression and Negative Binomial Regression</title>
      <link>/blog/poisson-regression-and-neg-ative-binomial-regression/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/poisson-regression-and-neg-ative-binomial-regression/</guid>
      <description>Introduction Regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or &amp;lsquo;predictors&amp;rsquo;).
For example  Find out the effect of land area and building area on house prices in the Kuningan region (Multiple Linear Regression)
 Find out the effect of allowance and GPA on cum laude predicate (yes or no) ?</description>
    </item>
    
    <item>
      <title>Introduction to tidymodels</title>
      <link>/blog/tidymodels/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/tidymodels/</guid>
      <description>The following presentation is produced by the team at Algoritma for its internal training This presentation is intended for a restricted audience only. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.
Outline Why tidymodels Matters?  Things we think we&amp;rsquo;re doing it right Things we never think we could do it better  Setting the Cross-Validation Scheme using rsample  Rethinking: Why we need validation?</description>
    </item>
    
    <item>
      <title>Creating Choropleth with Mapshaper and R</title>
      <link>/blog/creating-choropleth-with-mapshaper-and-r/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/creating-choropleth-with-mapshaper-and-r/</guid>
      <description>Geospatial is one of the important things in data processing. With geospatial, we can provide information only with the help of maps so that information can be conveyed properly.
There are many types of geospatial that we can do, such as Dot Map, Connection Map, Choropleth, Hexbin Map, and Bubble Map1. Each type of geospatial has its own function, and each of these types also requires different types of information/data.</description>
    </item>
    
    <item>
      <title>Self-Organizing Maps</title>
      <link>/blog/self-organizing-maps/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/self-organizing-maps/</guid>
      <description>body { text-align: justify}  Introduction Self-Organizing Maps (SOM) Self-Organizing Maps first introduce by Teuvo Kohonen. According to the Wiki, Self-Organizing Map (SOM) or self-organizing feature map (SOFM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a map, and is therefore a method to do dimensionality reduction.</description>
    </item>
    
    <item>
      <title>Age-Period-Cohort (APC) Analysis</title>
      <link>/blog/age-period-cohort-apc-analysis/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/age-period-cohort-apc-analysis/</guid>
      <description>Background Disclaimer The following coursebook is produced by the team at Algoritma for its Data Science Academy internal training. The coursebook is intended for a restricted audience only, i.e. the individuals and organizations having received this coursebook directly from the training organization. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.
Libraries and Setup You will need install the package to do APC analysis if it&amp;rsquo;s not already downloaded onto your machine.</description>
    </item>
    
    <item>
      <title>Twitter Interactions Analysis using Twinetverse</title>
      <link>/blog/twitter-interactions-analysis-using-twinetverse/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/twitter-interactions-analysis-using-twinetverse/</guid>
      <description>IntroductionThe goal of the twinetverse is to provide everything one might need to view Twitter interactions, from data collection to visualisation. This could be a powerful tool for social media analysis, since it could help visualizing how users communicate with one another on a given topic or how information spreads throughout the Twitter network.</description>
    </item>
    
    <item>
      <title>Purrr-operly Fitting Multiple Time Series Model</title>
      <link>/blog/purrr-operly-fitting-multiple-time-series-model/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/purrr-operly-fitting-multiple-time-series-model/</guid>
      <description>In this article, I will explain some basic functional programming for fitting multiple time series using R, particularly using purrr interface.
TL;DR: you can find the distraction-free script in here, and read some of my concluding remarks for a quick summary :grin:
PrefaceWhen it comes to time series analyses and forecasting, R users are blessed with an invaluable tools that could helps us to conveniently fit–from basic to advanced–univariate time series models: forecast package.</description>
    </item>
    
    <item>
      <title>Data Wars: Episode IV</title>
      <link>/blog/data-wars-episode-iv/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/data-wars-episode-iv/</guid>
      <description>Data wrangling sometimes could become very tedious. No matter what language do you prefer: R, python, or even SQL, the process of preprocessing your dataset is generally very time consuming. But, this is not the case if you know how to properly use packages included in tidyverse.
The term of tidyverse is actually referring to a set of packages that you’ll find very helpful in any data analysis tasks; many of them are already popular among R users, like dplyr, ggplot2, and lubridate.</description>
    </item>
    
    <item>
      <title>Text Preprocessing using textclean</title>
      <link>/blog/textclean/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/textclean/</guid>
      <description>Take tweet from twitter using rtweet packageFunction used for take tweet from twitter is search_tweets(). There are several parameter usually used in that function: - Topic : topic you will find at twitter - n : how many tweet that you want to take - include_rts : logical. If FALSE tweet taken didn’t contain retweet - lang : spesified language. If you want take tweet in english you can addargument lang = “en” You can use this code below to try taking tweets from twitter by removing the command</description>
    </item>
    
    <item>
      <title>Handling Duplicate Data</title>
      <link>/blog/handling-duplicate-data/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/handling-duplicate-data/</guid>
      <description>Reading Data and Basic PreprocessingSome data that we obtain from the internet are gained as a raw, means that there are no modifications done to the data except placing it in the right column or row. Even if that’s a good thing, sometimes you have to treat and change the template of the data to be as friendly to reach our objective as possible.
Making sure that there are no duplicated data is one of the aspect of understanding the data itself, because we can’t say that the model that are being made from the information full of duplicated data is relevant enough to be used in real-case scenario.</description>
    </item>
    
    <item>
      <title>Time Series Prediction with LSTM</title>
      <link>/blog/time-series-prediction-with-lstm/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/time-series-prediction-with-lstm/</guid>
      <description>Time Series Forecasting using LSTMTime series involves data collected sequentially in time. In Feed Forward Neural Network we describe that all inputs are not dependent on each other or are usually familiar as IID (Independent Identical Distributed), so it is not appropriate to use sequential data processing.A Recurrent Neural Network (RNN) deals with sequence problems because their connections form a directed cycle.</description>
    </item>
    
    <item>
      <title>Metrics Evaluation using `yardstick`</title>
      <link>/blog/metrics-evaluation-using-yardstick/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/metrics-evaluation-using-yardstick/</guid>
      <description>MotivationEvaluating your machine learning algorithms is important part in your project. Choice of metrics influences how the performance of machine learning algorithms is measured and compared. Metrics evaluation used to measure the performance of our algorithms. For Regression models, we usually use R-squared and MSE, but for Classification models we can use precision, recall and accuracy. Evaluating a classifier is often much more difficult than evaluating a regression algorithm.</description>
    </item>
    
    <item>
      <title>Nested Dataframe</title>
      <link>/blog/nested-dataframe/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/nested-dataframe/</guid>
      <description>1. SetupLibraries and SetupWe’ll set-up caching for this notebook given how computationally expensive some of the code we will write can get.
You will need to use install.packages() to install any packages that are not already downloaded onto your machine. You then load the package into your workspace using the library() function:
library(tidyverse)library(caret)2. Nested DataframeYou’ll learn how to use purrr, caret and dplyr to quickly create some of dataset + model combinations, store data &amp;amp; model objects neatly in one tibble, and post process programatically.</description>
    </item>
    
    <item>
      <title>Troubleshoot in R</title>
      <link>/blog/troubleshoot-in-r/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/troubleshoot-in-r/</guid>
      <description>IntroductionWhen you start coding in R you probably get a lot of errors, and trying to decipher an error can be a time-consuming task. You might need to Google or maybe you asked for help to your friends/mentor and they find out you’ve forgot a closing bracket!.
You just learnt about the importance of it just few hours ago, “You’re supposed to know this stuff”. You might be frustrated and blame yourself when you make very basic mistakes, but this is something every one goes through.</description>
    </item>
    
    <item>
      <title>Forecasting Time Series with Multiple Seasonal</title>
      <link>/blog/multiple-seasonal/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/multiple-seasonal/</guid>
      <description>IntroductionTime Series Analysis describes a set of research problems where our observations are collected at regular time intervals and where we can assume correlations among successive observations. The principal idea is to learn from these past observations any inherent structures or patterns within the data, with the objective of generating future values for the series. Time series may contain multiple seasonal cycles of different lengths. A fundamental goal for multiple seasonal (MS) processes is to allow for the seasonal terms that represent a seasonal cycle to be updated more than once during the period of the cycle.</description>
    </item>
    
    <item>
      <title>Text Cleaning Bahasa Indonesia-based Twitter Data</title>
      <link>/blog/text-cleaning-bahasa/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-cleaning-bahasa/</guid>
      <description>Social media has become a very popular spot for data mining these last years. But when we talk about social data, we actually also talk about unstructured data, and in order to derive any meaningful insight from it, we have to know how to work with it in its unstructured form (or in this case, unstructured text information).
Before the data we gather can be used for further analysis, the very first step to do is to clean the data.</description>
    </item>
    
    <item>
      <title>Causal Inference and Bayesian Network</title>
      <link>/blog/causal-inference-and-bayesian-network/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/causal-inference-and-bayesian-network/</guid>
      <description>Introduction Cause has been people&amp;rsquo;s curiosity for a long time, you can see that people often ask &amp;ldquo;Why&amp;rdquo; to things happening around them. But do we actually know how to explain &amp;ldquo;cause&amp;rdquo;?
Do we jump to conclusion of causal relationship often too quickly?
Can association between factors that we call mathematically &amp;ldquo;correlation&amp;rdquo; tell us possible causal relationship? No. Correlation shows whether two variable go up or down together. But just because two variables go up together doesn&amp;rsquo;t mean it affects each other.</description>
    </item>
    
    <item>
      <title>Support Vector Machine</title>
      <link>/blog/support-vector-machine/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/support-vector-machine/</guid>
      <description>Support Vector Machine (SVM) Support Vector Machine is a Supervised Machine Learning Algorithm which can be used both classification and regression. In this algorithm, each data item is plotted as point in n-dimensional space with the value of each feature being the value of a particular coordinate. Then, the algorithm perform classification by finding the hyper-plane that differentiate the two classes very well.
So how does SVM find the right hyperplane?</description>
    </item>
    
    <item>
      <title>Fancy App 1</title>
      <link>/itemized/item1/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item1/</guid>
      <description> App 1 </description>
    </item>
    
    <item>
      <title>Fancy App 2</title>
      <link>/itemized/item2/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item2/</guid>
      <description> App 2 </description>
    </item>
    
    <item>
      <title>Fancy App 3</title>
      <link>/itemized/item3/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item3/</guid>
      <description> App 3 </description>
    </item>
    
    <item>
      <title>Fancy App 4</title>
      <link>/itemized/item4/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item4/</guid>
      <description> App 4 </description>
    </item>
    
    <item>
      <title></title>
      <link>/blog/2019-10-22-poisson-regression-and-negative-binomial-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019-10-22-poisson-regression-and-negative-binomial-regression/</guid>
      <description>Poisson Regression and Negative Binomial Regression/*! jQuery v1.11.3 | (c) 2005, 2015 jQuery Foundation, Inc. | jquery.org/license */!function(a,b){&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return b(a)}:b(a)}(&#34;undefined&#34;!=typeof window?window:this,function(a,b){var c=[],d=c.slice,e=c.concat,f=c.push,g=c.indexOf,h={},i=h.toString,j=h.hasOwnProperty,k={},l=&#34;1.11.3&#34;,m=function(a,b){return new m.fn.init(a,b)},n=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,o=/^-ms-/,p=/-([\da-z])/gi,q=function(a,b){return b.toUpperCase()};m.fn=m.prototype={jquery:l,constructor:m,selector:&#34;&#34;,length:0,toArray:function(){return d.call(this)},get:function(a){return null!=a?0a?this[a+this.length]:this[a]:d.call(this)},pushStack:function(a){var b=m.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a,b){return m.each(this,a,b)},map:function(a){return this.pushStack(m.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(d.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0a?b:0);return this.pushStack(c=0&amp;&amp;bc?[this[c]]:[])},end:function(){return this.prevObject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},m.extend=m.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for(&#34;boolean&#34;==typeof g&amp;&amp;(j=g,g=arguments[h]||{},h++),&#34;object&#34;==typeof g||m.isFunction(g)||(g={}),h===i&amp;&amp;(g=this,h--);ih;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&amp;&amp;(j&amp;&amp;c&amp;&amp;(m.isPlainObject(c)||(b=m.isArray(c)))?(b?(b=!1,f=a&amp;&amp;m.isArray(a)?a:[]):f=a&amp;&amp;m.isPlainObject(a)?a:{},g[d]=m.extend(j,f,c)):void 0!==c&amp;&amp;(g[d]=c));return g},m.extend({expando:&#34;jQuery&#34;+(l+Math.random()).replace(/\D/g,&#34;&#34;),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return&#34;function&#34;===m.type(a)},isArray:Array.isArray||function(a){return&#34;array&#34;===m.type(a)},isWindow:function(a){return null!=a&amp;&amp;a==a.window},isNumeric:function(a){return!m.isArray(a)&amp;&amp;a-parseFloat(a)+1=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||&#34;object&#34;!==m.type(a)||a.nodeType||m.isWindow(a))return!1;try{if(a.constructor&amp;&amp;!j.call(a,&#34;constructor&#34;)&amp;&amp;!j.call(a.constructor.prototype,&#34;isPrototypeOf&#34;))return!1}catch(c){return!1}if(k.ownLast)for(b in a)return j.call(a,b);for(b in a);return void 0===b||j.</description>
    </item>
    
  </channel>
</rss>