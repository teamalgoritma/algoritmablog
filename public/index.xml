<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algoritma Technical Blog</title>
    <link>/</link>
    <description>Recent content on Algoritma Technical Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Creating Choropleth with Mapshaper and R</title>
      <link>/blog/creating-choropleth-with-mapshaper-and-r/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/creating-choropleth-with-mapshaper-and-r/</guid>
      <description>Geospatial is one of the important things in data processing. With geospatial, we can provide information only with the help of maps so that information can be conveyed properly.
There are many types of geospatial that we can do, such as Dot Map, Connection Map, Choropleth, Hexbin Map, and Bubble Map1. Each type of geospatial has its own function, and each of these types also requires different types of information/data.</description>
    </item>
    
    <item>
      <title>Self-Organizing Maps</title>
      <link>/blog/self-organizing-maps/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/self-organizing-maps/</guid>
      <description>Introduction SOM Self-Organizing Maps first introduce by Teuvo Kohonen. According to the Wiki, Self-Organizing Map (SOM) or self-organizing feature map (SOFM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a map, and is therefore a method to do dimensionality reduction.[^1] SOM are an unsupervised data visualisation technique that can be used to visualise high-dimensional data sets in lower (typically 2) dimensional representations.</description>
    </item>
    
    <item>
      <title>Age-Period-Cohort (APC) Analysis</title>
      <link>/blog/age-period-cohort-apc-analysis/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/age-period-cohort-apc-analysis/</guid>
      <description>Background Disclaimer The following coursebook is produced by the team at Algoritma for its Data Science Academy internal training. The coursebook is intended for a restricted audience only, i.e. the individuals and organizations having received this coursebook directly from the training organization. It may not be reproduced, distributed, translated or adapted in any form outside these individuals and organizations without permission.
Libraries and Setup You will need install the package to do APC analysis if it&amp;rsquo;s not already downloaded onto your machine.</description>
    </item>
    
    <item>
      <title>Twitter Interactions Analysis using Twinetverse</title>
      <link>/blog/twitter-interactions-analysis-using-twinetverse/</link>
      <pubDate>Thu, 28 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/twitter-interactions-analysis-using-twinetverse/</guid>
      <description>IntroductionThe goal of the twinetverse is to provide everything one might need to view Twitter interactions, from data collection to visualisation. This could be a powerful tool for social media analysis, since it could help visualizing how users communicate with one another on a given topic or how information spreads throughout the Twitter network.</description>
    </item>
    
    <item>
      <title>Purrr-operly Fitting Multiple Time Series Model</title>
      <link>/blog/purrr-operly-fitting-multiple-time-series-model/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/purrr-operly-fitting-multiple-time-series-model/</guid>
      <description>In this article, I will explain some basic functional programming for fitting multiple time series using R, particularly using purrr interface.
TL;DR: you can find the distraction-free script in here, and read some of my concluding remarks for a quick summary :grin:
PrefaceWhen it comes to time series analyses and forecasting, R users are blessed with an invaluable tools that could helps us to conveniently fit–from basic to advanced–univariate time series models: forecast package.</description>
    </item>
    
    <item>
      <title>Data Wars: Episode IV</title>
      <link>/blog/data-wars-episode-iv/</link>
      <pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/data-wars-episode-iv/</guid>
      <description>Data wrangling sometimes could become very tedious. No matter what language do you prefer: R, python, or even SQL, the process of preprocessing your dataset is generally very time consuming. But, this is not the case if you know how to properly use packages included in tidyverse.
The term of tidyverse is actually referring to a set of packages that you’ll find very helpful in any data analysis tasks; many of them are already popular among R users, like dplyr, ggplot2, and lubridate.</description>
    </item>
    
    <item>
      <title>Text Preprocessing using textclean</title>
      <link>/blog/textclean/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/textclean/</guid>
      <description>Take tweet from twitter using rtweet packageFunction used for take tweet from twitter is search_tweets(). There are several parameter usually used in that function: - Topic : topic you will find at twitter - n : how many tweet that you want to take - include_rts : logical. If FALSE tweet taken didn’t contain retweet - lang : spesified language. If you want take tweet in english you can addargument lang = “en” You can use this code below to try taking tweets from twitter by removing the command</description>
    </item>
    
    <item>
      <title>Handling Duplicate Data</title>
      <link>/blog/handling-duplicate-data/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/handling-duplicate-data/</guid>
      <description>Reading Data and Basic PreprocessingSome data that we obtain from the internet are gained as a raw, means that there are no modifications done to the data except placing it in the right column or row. Even if that’s a good thing, sometimes you have to treat and change the template of the data to be as friendly to reach our objective as possible.
Making sure that there are no duplicated data is one of the aspect of understanding the data itself, because we can’t say that the model that are being made from the information full of duplicated data is relevant enough to be used in real-case scenario.</description>
    </item>
    
    <item>
      <title>Time Series Prediction with LSTM</title>
      <link>/blog/time-series-prediction-with-lstm/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/time-series-prediction-with-lstm/</guid>
      <description>Time Series Forecasting using LSTMTime series involves data collected sequentially in time. In Feed Forward Neural Network we describe that all inputs are not dependent on each other or are usually familiar as IID (Independent Identical Distributed), so it is not appropriate to use sequential data processing.A Recurrent Neural Network (RNN) deals with sequence problems because their connections form a directed cycle.</description>
    </item>
    
    <item>
      <title>Metrics Evaluation using `yardstick`</title>
      <link>/blog/metrics-evaluation-using-yardstick/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/metrics-evaluation-using-yardstick/</guid>
      <description>MotivationEvaluating your machine learning algorithms is important part in your project. Choice of metrics influences how the performance of machine learning algorithms is measured and compared. Metrics evaluation used to measure the performance of our algorithms. For Regression models, we usually use R-squared and MSE, but for Classification models we can use precision, recall and accuracy. Evaluating a classifier is often much more difficult than evaluating a regression algorithm.</description>
    </item>
    
    <item>
      <title>Nested Dataframe</title>
      <link>/blog/nested-dataframe/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/nested-dataframe/</guid>
      <description>1. SetupLibraries and SetupWe’ll set-up caching for this notebook given how computationally expensive some of the code we will write can get.
You will need to use install.packages() to install any packages that are not already downloaded onto your machine. You then load the package into your workspace using the library() function:
library(tidyverse)library(caret)2. Nested DataframeYou’ll learn how to use purrr, caret and dplyr to quickly create some of dataset + model combinations, store data &amp;amp; model objects neatly in one tibble, and post process programatically.</description>
    </item>
    
    <item>
      <title>Troubleshoot in R</title>
      <link>/blog/troubleshoot-in-r/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/troubleshoot-in-r/</guid>
      <description>IntroductionWhen you start coding in R you probably get a lot of errors, and trying to decipher an error can be a time-consuming task. You might need to Google or maybe you asked for help to your friends/mentor and they find out you’ve forgot a closing bracket!.
You just learnt about the importance of it just few hours ago, “You’re supposed to know this stuff”. You might be frustrated and blame yourself when you make very basic mistakes, but this is something every one goes through.</description>
    </item>
    
    <item>
      <title>Forecasting Time Series with Multiple Seasonal</title>
      <link>/blog/multiple-seasonal/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/multiple-seasonal/</guid>
      <description>IntroductionTime Series Analysis describes a set of research problems where our observations are collected at regular time intervals and where we can assume correlations among successive observations. The principal idea is to learn from these past observations any inherent structures or patterns within the data, with the objective of generating future values for the series. Time series may contain multiple seasonal cycles of different lengths. A fundamental goal for multiple seasonal (MS) processes is to allow for the seasonal terms that represent a seasonal cycle to be updated more than once during the period of the cycle.</description>
    </item>
    
    <item>
      <title>Text Cleaning Bahasa Indonesia-based Twitter Data</title>
      <link>/blog/text-cleaning-bahasa/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/text-cleaning-bahasa/</guid>
      <description>Social media has become a very popular spot for data mining these last years. But when we talk about social data, we actually also talk about unstructured data, and in order to derive any meaningful insight from it, we have to know how to work with it in its unstructured form (or in this case, unstructured text information).
Before the data we gather can be used for further analysis, the very first step to do is to clean the data.</description>
    </item>
    
    <item>
      <title>Causal Inference and Bayesian Network</title>
      <link>/blog/causal-inference-and-bayesian-network/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/causal-inference-and-bayesian-network/</guid>
      <description>Introduction Cause has been people&amp;rsquo;s curiosity for a long time, you can see that people often ask &amp;ldquo;Why&amp;rdquo; to things happening around them. But do we actually know how to explain &amp;ldquo;cause&amp;rdquo;?
Do we jump to conclusion of causal relationship often too quickly?
Can association between factors that we call mathematically &amp;ldquo;correlation&amp;rdquo; tell us possible causal relationship? No. Correlation shows whether two variable go up or down together. But just because two variables go up together doesn&amp;rsquo;t mean it affects each other.</description>
    </item>
    
    <item>
      <title>Support Vector Machine</title>
      <link>/blog/support-vector-machine/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/support-vector-machine/</guid>
      <description>Support Vector Machine (SVM) Support Vector Machine is a Supervised Machine Learning Algorithm which can be used both classification and regression. In this algorithm, each data item is plotted as point in n-dimensional space with the value of each feature being the value of a particular coordinate. Then, the algorithm perform classification by finding the hyper-plane that differentiate the two classes very well.
So how does SVM find the right hyperplane?</description>
    </item>
    
    <item>
      <title>Fancy App 1</title>
      <link>/itemized/item1/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item1/</guid>
      <description> App 1 </description>
    </item>
    
    <item>
      <title>Fancy App 2</title>
      <link>/itemized/item2/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item2/</guid>
      <description> App 2 </description>
    </item>
    
    <item>
      <title>Fancy App 3</title>
      <link>/itemized/item3/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item3/</guid>
      <description> App 3 </description>
    </item>
    
    <item>
      <title>Fancy App 4</title>
      <link>/itemized/item4/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/itemized/item4/</guid>
      <description> App 4 </description>
    </item>
    
  </channel>
</rss>